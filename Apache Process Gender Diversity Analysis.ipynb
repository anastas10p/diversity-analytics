{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook seeks to explore the gender diversity of the different apache projects & the process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2018-08-22 22:21:02--  https://raw.githubusercontent.com/holdenk/diversity-analytics/master/lazy_helpers.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1397 (1.4K) [text/plain]\n",
      "Saving to: ‘lazy_helpers.py’\n",
      "\n",
      "lazy_helpers.py     100%[===================>]   1.36K  --.-KB/s    in 0s      \n",
      "\n",
      "2018-08-22 22:21:03 (45.8 MB/s) - ‘lazy_helpers.py’ saved [1397/1397]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Kind of a hack because of the Spark notebook serialization issues\n",
    "!rm lazy_helpers.py*\n",
    "!wget https://raw.githubusercontent.com/holdenk/diversity-analytics/master/lazy_helpers.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['yarn\\n',\n",
       " 'yarn\\n',\n",
       " 'yarn\\n',\n",
       " 'yarn\\n',\n",
       " 'yarn\\n',\n",
       " 'yarn\\n',\n",
       " 'yarn\\n',\n",
       " 'yarn\\n']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hack to update sparklingml on a running cluster -\n",
    "#TODO(holden): release sparkling ml properly so no hacks\n",
    "memory_status_count = sc._jsc.sc().getExecutorMemoryStatus().size()\n",
    "estimated_executors = max(sc.defaultParallelism, memory_status_count)\n",
    "rdd = sc.parallelize(range(estimated_executors))\n",
    "def do_update(x):\n",
    "    import os\n",
    "    return str(os.popen(\"whoami && cd /sparklingml && git pull && git log -n 5\").read())\n",
    "result = rdd.map(do_update)\n",
    "result.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PATH'] = os.environ['PATH'] + \":/usr/lib/chromium/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import *\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import concat, collect_set, explode, from_json, format_string\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.session import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "import json\n",
    "import os\n",
    "import meetup.api\n",
    "from copy import copy\n",
    "import time\n",
    "import logging\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "API key configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load gh_api_token & meetup_key & genderize_key\n",
    "exec(open(\"./secrets.literal\").read())\n",
    "gh_user = \"holdenk\"\n",
    "fs_prefix = \"gs://boo-stuff/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Less secret configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_meetup_events = 800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SparkSession.builder.getOrCreate().stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = (SparkSession.builder\n",
    "           .appName(\"whatCanWeLearnFromTheSixties\")\n",
    "           .config(\"spark.executor.instances\", \"45\")\n",
    "           .config(\"spark.driver.memoryOverhead\", \"0.25\")\n",
    "           .config(\"spark.executor.memory\", \"16g\")\n",
    "           .config(\"spark.dynamicAllocation.enabled\", \"false\")\n",
    "           .config(\"spark.ui.enabled\", \"true\")\n",
    "          ).getOrCreate()\n",
    "sc = session.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'holden-magic-m:18080'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In _theory_ in preview dataproc Spark UI is force disabled but history fills the gap, except history server isn't started by default :(\n",
    "sc.getConf().get(\"spark.yarn.historyServer.address\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we want to get is the committers and PMC members, this information is stored in LDAP but also available in JSON. Eventually we will want to enrich this with mailing list information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadFlatJsonFile(path, explodeKey, schema=None):\n",
    "    \"\"\"Load a flat multi-line json file and convert into Spark & explode\"\"\"\n",
    "    rdd = sc.wholeTextFiles(path).values().setName(\"Input file {}\".format(path))\n",
    "    df = (session.read.schema(schema)\n",
    "            .json(rdd))\n",
    "    return df.select(explode(explodeKey))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[username: string, extra: struct<name:string,key_fingerprints:array<string>,urls:array<string>>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apache_people_schema = StructType([StructField(\"lastCreateTimestamp\", StringType()),\n",
    "                     StructField(\"people\",\n",
    "                                 MapType(StringType(), \n",
    "                                         StructType([StructField('name', StringType()),\n",
    "                                                     StructField('key_fingerprints', ArrayType(StringType())),\n",
    "                                                     StructField('urls', ArrayType(StringType())),\n",
    "                                                    ]))\n",
    "                                )])\n",
    "apache_poeple_df_file = \"{0}{1}\".format(fs_prefix, \"http_data_sources/public_ldap_people.json\") # http://people.apache.org/public/public_ldap_people.json\n",
    "apache_people_df = loadFlatJsonFile(path=apache_poeple_df_file, \n",
    "                                 explodeKey=\"people\", schema=apache_people_schema)\n",
    "apache_people_df = apache_people_df.select(apache_people_df.key.alias(\"username\"), apache_people_df.value.alias(\"extra\")).repartition(100).persist().alias(\"apache_people\")\n",
    "apache_people_df.alias(\"Apache Committers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.addFile(\"lazy_helpers.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lazy_helpers.LazyPool"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construct a lazy urllib3 pool\n",
    "from lazy_helpers import *\n",
    "    \n",
    "bcast_pool = sc.broadcast(LazyPool)\n",
    "bcast_pool.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_on_github(project):\n",
    "    \"\"\"Returns if a project is on github\"\"\"\n",
    "    import urllib3\n",
    "    http = bcast_pool.value.get()\n",
    "    r = http.request('GET', \"https://github.com/apache/{0}\".format(project))\n",
    "    return r.status == 200\n",
    "session.catalog.registerFunction(\"on_github\", project_on_github, BooleanType())\n",
    "# Except I'm a bad person so....\n",
    "from pyspark.sql.catalog import UserDefinedFunction\n",
    "project_on_github_udf = UserDefinedFunction(project_on_github, BooleanType(), \"on_github\")\n",
    "session.catalog._jsparkSession.udf().registerPython(\"on_github\", project_on_github_udf._judf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "163"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apache_committees_schema = StructType([StructField(\"lastCreateTimestamp\", StringType()),\n",
    "                     StructField(\"committees\",\n",
    "                                 MapType(StringType(), StructType([StructField('roster', ArrayType(StringType())),\n",
    "                                                                  StructField('modifyTimestamp', StringType()),\n",
    "                                                                  StructField('createTimestamp', StringType())\n",
    "                                                                  ])))])\n",
    "apache_committees_df_file = \"{0}{1}\".format(fs_prefix, \"http_data_sources/public_ldap_committees.json\") # http://people.apache.org/public/public_ldap_committees.json\n",
    "apache_committees_df = loadFlatJsonFile(path=apache_committees_df_file,\n",
    "                                 explodeKey=\"committees\", schema=apache_committees_schema)\n",
    "apache_committees_on_github_df = apache_committees_df.filter(project_on_github_udf(apache_committees_df.key))\n",
    "apache_committees_on_github_df.persist(StorageLevel.MEMORY_AND_DISK)\n",
    "committee_names_df = apache_committees_on_github_df.select(apache_committees_df.key.alias(\"project\")).alias(\"apache_committees\").repartition(200)\n",
    "committee_names_df.persist(StorageLevel.MEMORY_AND_DISK)\n",
    "committee_names_df.alias(\"Apache Committee Names\")\n",
    "committee_names_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[username: string, extra: struct<name:string,key_fingerprints:array<string>,urls:array<string>>, projects: array<string>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_to_user_df = apache_committees_on_github_df.select(\n",
    "    apache_committees_on_github_df.key.alias(\"project\"),\n",
    "    explode(apache_committees_on_github_df.value.roster).alias(\"username\"))\n",
    "\n",
    "\n",
    "user_to_project_df = project_to_user_df.groupBy(project_to_user_df.username).agg(\n",
    "    collect_set(project_to_user_df.project).alias(\"projects\"))\n",
    "apache_people_df = apache_people_df.join(user_to_project_df, on=\"username\")\n",
    "apache_people_df.alias(\"Apache People joined with projects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(username='macdonst', extra=Row(name='Simon MacDonald', key_fingerprints=None, urls=None), projects=['cordova'])]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apache_people_df.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attempt to fetch relevant past & present meetups for each project - idea based on the listing at https://www.apache.org/events/meetups.html but different code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to do a non-blocking count to materialize the meetup RDD because this is slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some async helpers, in Scala we would use AsyncRDDActions but its not currently available in Python\n",
    "# Support is being considered in https://issues.apache.org/jira/browse/SPARK-20347\n",
    "def non_blocking_rdd_count(rdd):\n",
    "    import threading\n",
    "    def count_magic():\n",
    "        rdd.count()\n",
    "    thread = threading.Thread(target=count_magic)\n",
    "    thread.start()\n",
    "\n",
    "def non_blocking_rdd_save(rdd, target):\n",
    "    import threading\n",
    "    def save_panda():\n",
    "        rdd.saveAsPickleFile(target)\n",
    "    thread = threading.Thread(target=save_panda)\n",
    "    thread.start()\n",
    "\n",
    "def non_blocking_df_save(df, target):\n",
    "    import threading\n",
    "    def save_panda():\n",
    "        df.write.mode(\"overwrite\").save(target)\n",
    "    thread = threading.Thread(target=save_panda)\n",
    "    thread.start()\n",
    "\n",
    "def non_blocking_df_save_csv(df, target):\n",
    "    import threading\n",
    "    def save_panda():\n",
    "        df.write.format(\"csv\").mode(\"overwrite\") \\\n",
    "            .option(\"header\", \"true\") \\\n",
    "            .option(\"quoteAll\", \"false\") \\\n",
    "            .save(target)\n",
    "    thread = threading.Thread(target=save_panda)\n",
    "    thread.start()\n",
    "\n",
    "def non_blocking_df_save_or_load(df, target):\n",
    "    fs = sc._jvm.org.apache.hadoop.fs.FileSystem.get(sc._jvm.java.net.URI(fs_prefix), sc._jsc.hadoopConfiguration())\n",
    "    success_files = [\"{0}/SUCCESS.txt\", \"{0}/_SUCCESS\"]\n",
    "    if any(fs.exists(sc._jvm.org.apache.hadoop.fs.Path(t.format(target))) for t in success_files):\n",
    "        print(\"Reusing\")\n",
    "        return session.read.load(target).persist()\n",
    "    else:\n",
    "        print(\"Saving\")\n",
    "        non_blocking_df_save(df, target)\n",
    "        return df\n",
    "\n",
    "def non_blocking_df_save_or_load_csv(df, target):\n",
    "    fs = sc._jvm.org.apache.hadoop.fs.FileSystem.get(sc._jvm.java.net.URI(fs_prefix), sc._jsc.hadoopConfiguration())\n",
    "    success_files = [\"{0}/SUCCESS.txt\", \"{0}/_SUCCESS\"]\n",
    "    if any(fs.exists(sc._jvm.org.apache.hadoop.fs.Path(t.format(target))) for t in success_files):\n",
    "        print(\"Reusing\")\n",
    "        return session.read.format(\"csv\").option(\"header\", \"true\") \\\n",
    "                .option(\"inferSchema\", \"true\").load(target).persist()\n",
    "    else:\n",
    "        print(\"Saving\")\n",
    "        non_blocking_df_save_csv(df, target)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger()\n",
    "logger.setLevel(\"WARN\")\n",
    "# For now, this is an avenue of future exploration, AKA holden's doesn't want her meetup API keys banned\n",
    "def lookup_relevant_meetup(project_name, max_meetup_events=0):\n",
    "    \"\"\"Lookup relevant meetups for a specific project.\"\"\"\n",
    "    import logging\n",
    "    import time\n",
    "    import meetup.api\n",
    "    logger = logging.getLogger()\n",
    "    meetup_delay = 30\n",
    "    meetup_reset_delay = 3600 # 1 hour\n",
    "    standard_keys = {\"text_format\": \"plain\", \"trending\": \"desc=true\", \"and_text\": \"true\", \"city\": \"san francisco\", \"country\": \"usa\", \"text\": \"apache \" + project_name, \"radius\": 10000}\n",
    "    results = {\"upcoming\": [], \"past\": []}\n",
    "    for status in [\"upcoming\", \"past\"]:\n",
    "        keys = copy(standard_keys)\n",
    "        keys[\"status\"] = status\n",
    "        count = 200\n",
    "        base = 0\n",
    "        while (count == 200 and (max_meetup_events == 0 or base < max_meetup_events)):\n",
    "            logging.debug(\"Fetch {0} meetups for {1} on base {2}\".format(status, project_name, base))\n",
    "            project_name = \"spark\"\n",
    "            client = client = meetup.api.Client(meetup_key)\n",
    "            if base > 0:\n",
    "                keys[\"page\"] = base\n",
    "            # Manually sleep for meetup_reset_delay on failure, the meetup-api package retry logic sometimes breaks :(\n",
    "            response = None\n",
    "            retry_count = 0\n",
    "            while response is None and retry_count < 10:\n",
    "                try:\n",
    "                    response = client.GetOpenEvents(**keys)\n",
    "                except:\n",
    "                    response = None\n",
    "                    retry_count += 1\n",
    "                    time.sleep(meetup_reset_delay)\n",
    "                    try:\n",
    "                        response = client.GetOpenEvents(**keys)\n",
    "                    except:\n",
    "                        response = None\n",
    "            try:\n",
    "                count = response.meta['count']\n",
    "                base = base + count\n",
    "                results[status].append(response.results)\n",
    "                time.sleep(meetup_delay)\n",
    "            except:\n",
    "                count = 0\n",
    "    return (project_name, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Meetup Data RDD PythonRDD[72] at RDD at PythonRDD.scala:48"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_meetups_rdd = committee_names_df.repartition(500).rdd.map(lambda x: x.project).map(lambda name: lookup_relevant_meetup(name, max_meetup_events))\n",
    "project_meetups_rdd.setName(\"Meetup Data RDD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#project_meetups_rdd.persist(StorageLevel.MEMORY_AND_DISK)\n",
    "#raw_project_meetups_df = project_meetups_rdd.toDF() \n",
    "#raw_project_meetups_df.alias(\"Project -> meetup dataframe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#project_meetups_df = non_blocking_df_save_or_load(\n",
    "#    raw_project_meetups_df, \"mini_meetup_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#project_meetups_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#project_meetups_df.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the provided projects attempt to lookup their GitHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup_project_git(org, project):\n",
    "    \"\"\"Returns the project github for a specific project. Assumes project is git hosted\"\"\"\n",
    "    return \"https://github.com/{0}/{1}.git\".format(org, project)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_project_github_data(org, project):\n",
    "    \"\"\"Fetch the project github data, note this only gets github issues so likely not super useful\"\"\"\n",
    "    from perceval.backends.core.github import GitHub as perceval_github\n",
    "    gh_backend = perceval_github(owner=org, repository=project, api_token=gh_api_token)\n",
    "    # The backend return a generator - which is awesome. However since we want to pull this data into Spark \n",
    "    def append_project_info(result):\n",
    "        \"\"\"Add the project information to the return from perceval\"\"\"\n",
    "        result[\"project_name\"] = project\n",
    "        return result\n",
    "\n",
    "    return list(map(append_project_info, gh_backend.fetch()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_project_git_data(org, project):\n",
    "    from perceval.backends.core.git import Git as perceval_git\n",
    "\n",
    "    git_uri = lookup_project_git(org, project)\n",
    "    import tempfile\n",
    "    import shutil\n",
    "    tempdir = tempfile.mkdtemp()\n",
    "\n",
    "    def append_project_info(result):\n",
    "        \"\"\"Add the project information to the return from perceval\"\"\"\n",
    "        result[\"project_name\"] = project\n",
    "        return result\n",
    "\n",
    "    try:\n",
    "        git_backend = perceval_git(uri=git_uri, gitpath=tempdir + \"/repo\")\n",
    "        return list(map(append_project_info, git_backend.fetch()))\n",
    "    finally:\n",
    "        shutil.rmtree(tempdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch the git history info using perceval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceival GIT dat UnionRDD[84] at union at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apache_git_project_data_rdd = committee_names_df.repartition(400).rdd.flatMap(lambda row: fetch_project_git_data(\"apache\", row.project))\n",
    "jupyter_git_project_data_rdd = sc.parallelize([(\"jupyter\", \"notebook\"), (\"nteract\", \"nteract\")]).flatMap(lambda elem: fetch_project_git_data(elem[0], elem[1]))\n",
    "git_project_data_rdd = apache_git_project_data_rdd.union(jupyter_git_project_data_rdd)\n",
    "git_project_data_rdd.setName(\"Perceival GIT dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reusing\n"
     ]
    }
   ],
   "source": [
    "git_project_data_df_raw = git_project_data_rdd.map(lambda row: Row(**row)).toDF().persist()\n",
    "git_project_data_df = non_blocking_df_save_or_load(git_project_data_df_raw, \"{0}/raw_git_data\".format(fs_prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(backend_name,StringType,true),StructField(backend_version,StringType,true),StructField(category,StringType,true),StructField(data,MapType(StringType,StringType,true),true),StructField(origin,StringType,true),StructField(perceval_version,StringType,true),StructField(project_name,StringType,true),StructField(tag,StringType,true),StructField(timestamp,DoubleType,true),StructField(updated_on,DoubleType,true),StructField(uuid,StringType,true)))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "git_project_data_df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_authors_by_project_and_commit_df = git_project_data_df.select(\"project_name\", \"data.Author\", \"data.CommitDate\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+--------------------+\n",
      "|project_name|              Author|          CommitDate|\n",
      "+------------+--------------------+--------------------+\n",
      "|      wicket|Eelco Hillenius <...|Tue Sep 21 18:49:...|\n",
      "|      wicket|Eelco Hillenius <...|Tue Sep 21 20:13:...|\n",
      "|      wicket|Martijn Dashorst ...|Wed Sep 22 00:02:...|\n",
      "|      wicket|Martijn Dashorst ...|Wed Sep 22 06:17:...|\n",
      "|      wicket|Martijn Dashorst ...|Wed Sep 22 06:44:...|\n",
      "|      wicket|Eelco Hillenius <...|Wed Sep 22 07:33:...|\n",
      "|      wicket|Eelco Hillenius <...|Wed Sep 22 09:25:...|\n",
      "|      wicket|Eelco Hillenius <...|Wed Sep 22 11:03:...|\n",
      "|      wicket|Eelco Hillenius <...|Wed Sep 22 13:53:...|\n",
      "|      wicket|Martijn Dashorst ...|Wed Sep 22 19:35:...|\n",
      "|      wicket|Martijn Dashorst ...|Wed Sep 22 20:38:...|\n",
      "|      wicket|Martijn Dashorst ...|Wed Sep 22 20:38:...|\n",
      "|      wicket|Johan Compagner <...|Wed Sep 22 21:20:...|\n",
      "|      wicket|Johan Compagner <...|Wed Sep 22 21:21:...|\n",
      "|      wicket|Eelco Hillenius <...|Mon Sep 27 12:36:...|\n",
      "|      wicket|Eelco Hillenius <...|Sun Oct 3 15:34:2...|\n",
      "|      wicket|Eelco Hillenius <...|Sun Oct 3 15:34:5...|\n",
      "|      wicket|Eelco Hillenius <...|Sun Oct 3 15:35:3...|\n",
      "|      wicket|Eelco Hillenius <...|Sun Oct 3 15:39:3...|\n",
      "|      wicket|Eelco Hillenius <...|Sun Oct 3 19:18:1...|\n",
      "+------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(project_name='wicket', Author='Eelco Hillenius <ehillenius@apache.org>', CommitDate='Tue Sep 21 18:49:10 2004 +0000')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_authors_by_project_and_commit_df.show()\n",
    "raw_authors_by_project_and_commit_df.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "@F.pandas_udf(StringType())\n",
    "def strip_junk(inputSeries):\n",
    "    \"\"\"Discard timezone information, who needs that anyways.\n",
    "    More accurately we don't care about that here since we're looking at a year long window.\"\"\"\n",
    "    return inputSeries.apply(lambda x: x.split(\"+\")[0])\n",
    "\n",
    "@F.pandas_udf(StringType())\n",
    "def extract_email(inputSeries):\n",
    "    \"\"\"Take e-mails of the form Foo Baz<foobaz@baz.com> and turn it into foobaz@baz.com\"\"\"\n",
    "    import re\n",
    "    def extract_email_record(record):\n",
    "        try:\n",
    "            emails = re.findall('<\\S+>$', record)\n",
    "            return emails[0]\n",
    "        except:\n",
    "            return record\n",
    "    \n",
    "    return inputSeries.apply(extract_email_record)\n",
    "\n",
    "@F.pandas_udf(StringType())\n",
    "def extract_name(inputSeries):\n",
    "    \"\"\"Take e-mails of the form Foo Baz<foobaz@baz.com> and turn it into the probable name e.g. Foo Baz\"\"\"\n",
    "    import re\n",
    "    def extract_name_record(record):\n",
    "        try:\n",
    "            emails = re.findall('([^<]+)<\\S+>$', record)\n",
    "            return emails[0]\n",
    "        except:\n",
    "            return \"\"\n",
    "    \n",
    "    return inputSeries.apply(extract_name_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_by_project_and_commit_df = raw_authors_by_project_and_commit_df.select(\n",
    "    \"project_name\", \"Author\", extract_email(\"Author\").alias(\"email\"), extract_name(\"Author\").alias(\"name\"),\n",
    "    F.to_date(strip_junk(\"CommitDate\"), format=\"EEE MMM d H:mm:ss YYYY \").alias(\"CommitDate\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(project_name,StringType,true),StructField(Author,StringType,true),StructField(email,StringType,true),StructField(name,StringType,true),StructField(CommitDate,DateType,true)))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authors_by_project_and_commit_df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[project_name: string, email: string, Author: string, latest_commit: date]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_distinct_authors_latest_commit = authors_by_project_and_commit_df.groupBy(\n",
    "    \"project_name\", \"email\").agg(\n",
    "    F.last(\"Author\").alias(\"Author\"), F.max(\"CommitDate\").alias(\"latest_commit\"))\n",
    "raw_distinct_authors_latest_commit.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reusing\n"
     ]
    }
   ],
   "source": [
    "distinct_authors_latest_commit = non_blocking_df_save_or_load(\n",
    "    raw_distinct_authors_latest_commit,\n",
    "    \"{0}distinct_authors_latest_commit_4\".format(fs_prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "@F.pandas_udf(StringType(), functionType=F.PandasUDFType.SCALAR)\n",
    "def lookup_github_user_by_email(emails):\n",
    "    \n",
    "    import time\n",
    "    from github import Github\n",
    "    import backoff\n",
    "    github_client = Github(gh_user, gh_api_token)\n",
    "    # In theory PyGithub handles backoff but we have multiple instances/machines.\n",
    "    @backoff.on_exception(backoff.expo, Exception)\n",
    "    def inner_lookup_github_user_by_email(email):\n",
    "        \"\"\"Lookup github user by e-mail address and returns the github username. Returns None if no user or more than 1 user is found.\"\"\"\n",
    "        users = github_client.search_users(\"{0}\".format(email))\n",
    "        def process_result(users):\n",
    "            if users.totalCount == 1:\n",
    "                return list(users).pop().login\n",
    "            else:\n",
    "                return \"\"\n",
    "\n",
    "        return process_result(users)\n",
    "\n",
    "    return emails.apply(inner_lookup_github_user_by_email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_to_github_username = distinct_authors_latest_commit.withColumn(\n",
    "    \"github_username\",\n",
    "    lookup_github_user_by_email(\"email\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "@F.pandas_udf(returnType=StringType(), functionType=F.PandasUDFType.SCALAR)\n",
    "def fetch_github_user_bio(logins):\n",
    "    from github import Github\n",
    "    import time\n",
    "    github_client = Github(gh_user, gh_api_token)\n",
    "    import backoff\n",
    "\n",
    "    @backoff.on_exception(backoff.expo, Exception)\n",
    "    def individual_fetch_github_user_bio(login):\n",
    "        if login == None or login == \"\":\n",
    "            return \"\"\n",
    "\n",
    "        result = github_client.get_user(login=login)\n",
    "        try:\n",
    "            return result.bio\n",
    "        except:\n",
    "            return \"\"\n",
    "    \n",
    "    return logins.apply(individual_fetch_github_user_bio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reusing\n"
     ]
    }
   ],
   "source": [
    "authors_to_github_username.persist()\n",
    "authors_to_github_username_saved = non_blocking_df_save_or_load(\n",
    "    authors_to_github_username,\n",
    "    \"{0}/authors_to_github-10\".format(fs_prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(project_name,StringType,true),StructField(email,StringType,true),StructField(Author,StringType,true),StructField(latest_commit,DateType,true)))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distinct_authors_latest_commit.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(project_name,StringType,true),StructField(email,StringType,true),StructField(Author,StringType,true),StructField(latest_commit,DateType,true),StructField(github_username,StringType,true)))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authors_to_github_username_saved.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "distinct_authors_with_gh = authors_to_github_username_saved.withColumn(\n",
    "    \"new_unique_id\",\n",
    "    F.when(F.col(\"github_username\") != \"\",\n",
    "         F.col(\"github_username\")).otherwise(\n",
    "        F.col(\"email\")))\n",
    "                                                                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_grouped_by_id = distinct_authors_with_gh.groupBy(\"project_name\", \"new_unique_id\").agg(\n",
    "    collect_set(F.col(\"email\")).alias(\"emails\"),\n",
    "    F.last(F.col(\"Author\")).alias(\"Author\"),\n",
    "    F.first(\"github_username\").alias(\"github_username\"),\n",
    "    F.max(\"latest_commit\").alias(\"latest_commit\"))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(project_name,StringType,true),StructField(new_unique_id,StringType,true),StructField(emails,ArrayType(StringType,true),true),StructField(Author,StringType,true),StructField(github_username,StringType,true),StructField(latest_commit,DateType,true)))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authors_grouped_by_id.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reusing\n"
     ]
    }
   ],
   "source": [
    "authors_grouped_by_id.persist()\n",
    "authors_grouped_by_id_saved = non_blocking_df_save_or_load(\n",
    "    authors_grouped_by_id,\n",
    "    \"{0}/authors_grouped_by_id-3\".format(fs_prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lookup info from crunchbase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/opt/conda/bin:/opt/conda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/lib/chromium/'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['PATH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lazy_helpers import *\n",
    "\n",
    "bcast_driver = sc.broadcast(LazyDriver)\n",
    "\n",
    "# TBD if we should see this, see comments on robots.txt in function, also consider overhead of firefox req\n",
    "def lookup_crunchbase_info(people_and_projects):\n",
    "    \"\"\"Lookup a person a crunch base and see what the gender & company is.\n",
    "    Filter for at least one mention of their projects.\"\"\"\n",
    "    # Path hack\n",
    "    if not \"chromium\" in os.environ['PATH']:\n",
    "        os.environ['PATH'] = os.environ['PATH'] + \":/usr/lib/chromium/\"\n",
    "    from bs4 import BeautifulSoup\n",
    "    import re\n",
    "    driver = bcast_driver.value.get()\n",
    "    import time\n",
    "    import random\n",
    "    for (username, name, projects, urls) in people_and_projects:\n",
    "        time.sleep(random.randint(60, 2*60))\n",
    "        # robots.txt seems to be ok with person for now as of April 4 2018, double check before re-running this\n",
    "        url = \"https://www.crunchbase.com/person/{0}\".format(name.replace(\" \", \"-\"))\n",
    "        try:\n",
    "            if driver.current_url != url:\n",
    "                driver.get(url)\n",
    "            text = driver.page_source\n",
    "            lower_text = text.lower()\n",
    "            yield[lower_text]\n",
    "            if \"the quick brown fox jumps over the lazy dog\" in lower_text or \"pardon our interruption...\" in lower_text:\n",
    "                time.sleep(random.randint(30*60, 2*60*60))\n",
    "                bcast_driver.value.reset()\n",
    "            if any(project.lower() in lower_text for project in projects) or any(url.lower in lower_text for url in urls):\n",
    "                soup = BeautifulSoup(text, \"html.parser\")\n",
    "                stats = soup.findAll(\"div\", { \"class\" : \"component--fields-card\"})[0]\n",
    "                # Hacky but I'm lazy\n",
    "                result = {}\n",
    "                result[\"crunchbase-url\"] = url\n",
    "                result[\"username\"] = username\n",
    "                if \"Female\" in str(stats):\n",
    "                    result[\"gender\"] = \"Female\"\n",
    "                if \"Male\" in str(stats):\n",
    "                    result[\"gender\"] = \"Male\"\n",
    "                try:\n",
    "                    m = re.search(\"\\\" title=\\\"(.+?)\\\" href=\\\"\\/organization\", lower_text)\n",
    "                    result[\"company\"] = m.group(1)\n",
    "                except:\n",
    "                    # No match no foul\n",
    "                    pass\n",
    "                yield result\n",
    "        except Exception as e:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result = lookup_crunchbase_info([(\"holden\", \"holden karau\", [\"spark\"], [\"http://www.holdenkarau.com\"])])\n",
    "#list(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Augment the committer info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[username: string, gender: string, company: string, crunchbase-url: string]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We do this as an RDD transformation since the cost of the transformation dominates\n",
    "relevant_info = apache_people_df.select(\n",
    "    apache_people_df.username,\n",
    "    apache_people_df.extra.getField(\"name\").alias(\"name\"),\n",
    "    apache_people_df.projects,\n",
    "    apache_people_df.extra.getField(\"urls\").alias(\"urls\"))\n",
    "crunchbase_info_rdd = relevant_info.rdd.map(lambda row: (row.username, row.name, row.projects, row.urls)).mapPartitions(lookup_crunchbase_info)\n",
    "crunchbase_info_rdd.persist(StorageLevel.MEMORY_AND_DISK)\n",
    "schema = StructType([\n",
    "    StructField(\"username\", StringType()),\n",
    "    StructField(\"gender\", StringType()),\n",
    "    StructField(\"company\", StringType()),\n",
    "    StructField(\"crunchbase-url\", StringType())])\n",
    "crunchbase_info_df = crunchbase_info_rdd.toDF(schema = schema)\n",
    "crunchbase_info_df.alias(\"Crunchbase user information\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving\n"
     ]
    }
   ],
   "source": [
    "crunchbase_info_df = non_blocking_df_save_or_load(\n",
    "    crunchbase_info_df,\n",
    "    \"{0}crunchbase_out_11\".format(fs_prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crunchbase_info_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2565"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apache_people_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(username,StringType,false),StructField(extra,StructType(List(StructField(name,StringType,true),StructField(key_fingerprints,ArrayType(StringType,true),true),StructField(urls,ArrayType(StringType,true),true))),true),StructField(projects,ArrayType(StringType,true),true)))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apache_people_df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export to Mechnical turk format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mini_concat_udf(array_strs):\n",
    "    \"\"\"Concat the array of strs\"\"\"\n",
    "    if array_strs == None:\n",
    "        return \"\"\n",
    "    else:\n",
    "        return ' '.join(array_strs)\n",
    "\n",
    "# Except I'm a bad person so....\n",
    "from pyspark.sql.catalog import UserDefinedFunction\n",
    "mini_concat_udf = UserDefinedFunction(mini_concat_udf, StringType(), \"mini_concat_udf\")\n",
    "session.catalog._jsparkSession.udf().registerPython(\"mini_concat_udf\", mini_concat_udf._judf)\n",
    "\n",
    "mini_csv_data_df = apache_people_df.select(\n",
    "    apache_people_df.username,\n",
    "    apache_people_df.extra.getField(\"name\").alias(\"name\"),\n",
    "    mini_concat_udf(apache_people_df.extra.getField(\"urls\")).alias(\"personal_websites\"),\n",
    "    mini_concat_udf(apache_people_df.projects).alias(\"projects\")\n",
    "    ).coalesce(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reusing\n"
     ]
    }
   ],
   "source": [
    "mini_csv_data_df = non_blocking_df_save_or_load_csv(\n",
    "    mini_csv_data_df,\n",
    "    \"{0}/apache_people.csv\".format(fs_prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crunchbase_info_rdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "One of the things that is interesting is understanding what the tones of the meetup descriptions & mailing list posts are. We can use https://www.ibm.com/watson/developercloud/tone-analyzer/api/v3/?python#introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: pandas UDF accelerate (but multiple pieces of informaiton returned at the same time)\n",
    "def lookup_sentiment(document):\n",
    "    \"\"\"Looks up the sentiment for a specific document.\"\"\"\n",
    "    from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "    # Hack to download if needed\n",
    "    # TODO(holden): Consider broadcast variable?\n",
    "    try:\n",
    "        sid = SentimentIntensityAnalyzer()\n",
    "    except LookupError:\n",
    "        import nltk\n",
    "        nltk.download('vader_lexicon')\n",
    "        sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    return sid.polarity_scores(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.781, 'pos': 0.219, 'compound': 0.3054}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookup_sentiment(\"Thanks! I still think it needs a bit more work, but.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.436, 'neu': 0.564, 'pos': 0.0, 'compound': -0.4754}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookup_sentiment(\"Who fucking broke the build?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Ok its time to find some mailing list info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_schema = StructType([\n",
    "    StructField(\"neg\", DoubleType()),\n",
    "    StructField(\"neu\", DoubleType()),\n",
    "    StructField(\"pos\", DoubleType()),\n",
    "    StructField(\"compound\", DoubleType())])\n",
    "\n",
    "lookup_sentiment_udf = UserDefinedFunction(\n",
    "    lookup_sentiment,\n",
    "    sentiment_schema,\n",
    "    \"lookup_sentiment_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbox_failures = sc.accumulator(0)\n",
    "\n",
    "def fetch_mbox_ids(project_name):\n",
    "    \"\"\"Return the mbox ids\"\"\"\n",
    "    import itertools\n",
    "\n",
    "    def fetch_mbox_ids_apache_site(box_type):\n",
    "        \"\"\"Fetches all of the mbox ids from a given apache project and box type (dev or user)\"\"\"\n",
    "        root_url = \"http://mail-archives.apache.org/mod_mbox/{0}-{1}\".format(project_name, box_type)\n",
    "        \n",
    "        # Fetch the page to parse\n",
    "        pool = bcast_pool.value.get()\n",
    "        result = pool.request('GET', root_url)\n",
    "        \n",
    "        \n",
    "        from bs4 import BeautifulSoup\n",
    "        soup = BeautifulSoup(result.data, \"html.parser\")\n",
    "        mbox_ids = set(map(lambda tag: tag.get('id'), soup.findAll(\"span\", { \"class\" : \"links\"})))\n",
    "        return map(lambda box_id: (project_name, box_type, box_id), mbox_ids)\n",
    "    # We have to return a list here because PySpark doesn't handle generators (TODO: holden)\n",
    "    return list(itertools.chain.from_iterable(map(fetch_mbox_ids_apache_site, [\"dev\", \"user\"])))\n",
    "        \n",
    "        \n",
    "def fetch_and_process_mbox_records(project_name, box_type, mbox_id):\n",
    "        import tempfile\n",
    "        import shutil\n",
    "        from perceval.backends.core.mbox import MBox as perceval_mbox\n",
    "\n",
    "        def process_mbox_directory(base_url, dir_path):\n",
    "            mbox_backend = perceval_mbox(base_url, dir_path)\n",
    "            return mbox_backend.fetch()\n",
    "        \n",
    "        def append_project_info(result):\n",
    "            \"\"\"Add the project information to the return from perceval\"\"\"\n",
    "            result[\"project_name\"] = project_name\n",
    "            result[\"box_type\"] = box_type\n",
    "            result[\"mbox_id\"] = mbox_id\n",
    "            return result\n",
    "\n",
    "        # Make a temp directory to hold the mbox files\n",
    "        tempdir = tempfile.mkdtemp()\n",
    "\n",
    "        try:\n",
    "            root_url = \"http://mail-archives.apache.org/mod_mbox/{0}-{1}\".format(project_name, box_type)\n",
    "            mbox_url = \"{0}/{1}.mbox\".format(root_url, mbox_id)\n",
    "            filename = \"{0}/{1}.mbox\".format(tempdir, mbox_id)\n",
    "        \n",
    "            print(\"fetching {0}\".format(mbox_url))\n",
    "\n",
    "            pool = bcast_pool.value.get()\n",
    "            with pool.request('GET', mbox_url, preload_content=False) as r, open(filename, 'wb') as out_file:       \n",
    "                try:\n",
    "                    shutil.copyfileobj(r, out_file)\n",
    "                    return list(map(append_project_info, process_mbox_directory(root_url, tempdir)))\n",
    "                except:\n",
    "                    mbox_failures.add(1)\n",
    "                    return []\n",
    "        finally:\n",
    "            shutil.rmtree(tempdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[216] at RDD at PythonRDD.scala:48"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def random_key(x):\n",
    "    import random\n",
    "    return (random.randint(0, 40000), x)\n",
    "\n",
    "def de_key(x):\n",
    "    return x[1]\n",
    "\n",
    "mailing_list_posts_mbox_ids = committee_names_df.repartition(400).rdd.flatMap(lambda row: fetch_mbox_ids(row.project))\n",
    "# mbox's can be big, so break up how many partitions we have\n",
    "mailing_list_posts_mbox_ids = mailing_list_posts_mbox_ids.map(random_key).repartition(2000).map(de_key)\n",
    "mailing_list_posts_rdd = mailing_list_posts_mbox_ids.flatMap(lambda args: fetch_and_process_mbox_records(*args))\n",
    "mailing_list_posts_rdd.persist(StorageLevel.MEMORY_AND_DISK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[project_name: string, box_type: string, mbox_id: string, backend_name: string, backend_version: string, category: string, data: map<string,string>, origin: string, perceval_version: string, tag: string, timestamp: double, updated_on: double, uuid: string]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"project_name\",StringType()),\n",
    "    StructField(\"box_type\",StringType()), # dev or user\n",
    "    StructField(\"mbox_id\",StringType()),\n",
    "    StructField(\"backend_name\",StringType()),\n",
    "    StructField(\"backend_version\",StringType()),\n",
    "    StructField(\"category\",StringType()),\n",
    "    StructField(\"data\", MapType(StringType(),StringType())), # The \"important\" bits\n",
    "    StructField(\"origin\",StringType()),\n",
    "    StructField(\"perceval_version\",StringType()),\n",
    "    StructField(\"tag\",StringType()),\n",
    "    StructField(\"timestamp\",DoubleType()),\n",
    "    StructField(\"updated_on\",DoubleType()),\n",
    "    StructField(\"uuid\",StringType())])\n",
    "mailing_list_posts_mbox_df_raw = mailing_list_posts_rdd.toDF(schema=schema)\n",
    "mailing_list_posts_mbox_df_raw.persist(StorageLevel.MEMORY_AND_DISK)\n",
    "mailing_list_posts_mbox_df_raw.alias(\"Mailing list perceival information - no post processing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reusing\n"
     ]
    }
   ],
   "source": [
    "mailing_list_posts_mbox_df_raw = non_blocking_df_save_or_load(\n",
    "    mailing_list_posts_mbox_df_raw,\n",
    "    \"{0}mailing_list_info_6\".format(fs_prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-18-2ddafa47624e>\", line 20, in save_panda\n",
      "    df.write.mode(\"overwrite\").save(target)\n",
      "  File \"/usr/lib/spark/python/pyspark/sql/readwriter.py\", line 703, in save\n",
      "    self._jwrite.save(path)\n",
      "  File \"/usr/lib/spark/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py\", line 1160, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/usr/lib/spark/python/pyspark/sql/utils.py\", line 63, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/usr/lib/spark/python/lib/py4j-0.10.6-src.zip/py4j/protocol.py\", line 320, in get_return_value\n",
      "    format(target_id, \".\", name), value)\n",
      "py4j.protocol.Py4JJavaError: An error occurred while calling o790.save.\n",
      ": org.apache.spark.SparkException: Job aborted.\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:224)\n",
      "\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:154)\n",
      "\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:104)\n",
      "\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:102)\n",
      "\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.doExecute(commands.scala:122)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:80)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:80)\n",
      "\tat org.apache.spark.sql.DataFrameWriter$$anonfun$runCommand$1.apply(DataFrameWriter.scala:654)\n",
      "\tat org.apache.spark.sql.DataFrameWriter$$anonfun$runCommand$1.apply(DataFrameWriter.scala:654)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:77)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:654)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:273)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:267)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:225)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 57 in stage 24.0 failed 4 times, most recent failure: Lost task 57.3 in stage 24.0 (TID 1182, holden-magic-sw-q7l8.c.boos-demo-projects-are-rad.internal, executor 39): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 229, in main\n",
      "    process()\n",
      "  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 224, in process\n",
      "    serializer.dump_stream(func(split_index, iterator), outfile)\n",
      "  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 372, in dump_stream\n",
      "    vs = list(itertools.islice(iterator, batch))\n",
      "  File \"/usr/lib/spark/python/pyspark/sql/session.py\", line 671, in prepare\n",
      "    verify_func(obj)\n",
      "  File \"/usr/lib/spark/python/pyspark/sql/types.py\", line 1421, in verify\n",
      "    verify_value(obj)\n",
      "  File \"/usr/lib/spark/python/pyspark/sql/types.py\", line 1400, in verify_struct\n",
      "    \"length of fields (%d)\" % (len(obj), len(verifiers))))\n",
      "ValueError: Length of object (1) does not match with length of fields (4)\n",
      "\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:298)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:438)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:421)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:252)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask(FileFormatWriter.scala:257)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$1.apply(FileFormatWriter.scala:197)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$1.apply(FileFormatWriter.scala:196)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:109)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586)\n",
      "\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)\n",
      "\tat scala.Option.foreach(Option.scala:257)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1820)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1769)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1758)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2027)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:194)\n",
      "\t... 30 more\n",
      "Caused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 229, in main\n",
      "    process()\n",
      "  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 224, in process\n",
      "    serializer.dump_stream(func(split_index, iterator), outfile)\n",
      "  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 372, in dump_stream\n",
      "    vs = list(itertools.islice(iterator, batch))\n",
      "  File \"/usr/lib/spark/python/pyspark/sql/session.py\", line 671, in prepare\n",
      "    verify_func(obj)\n",
      "  File \"/usr/lib/spark/python/pyspark/sql/types.py\", line 1421, in verify\n",
      "    verify_value(obj)\n",
      "  File \"/usr/lib/spark/python/pyspark/sql/types.py\", line 1400, in verify_struct\n",
      "    \"length of fields (%d)\" % (len(obj), len(verifiers))))\n",
      "ValueError: Length of object (1) does not match with length of fields (4)\n",
      "\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:298)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:438)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:421)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:252)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask(FileFormatWriter.scala:257)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$1.apply(FileFormatWriter.scala:197)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$1.apply(FileFormatWriter.scala:196)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:109)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\t... 1 more\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "records = mailing_list_posts_mbox_df_raw.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(project_name='juddi', box_type='dev', mbox_id='200506', backend_name='MBox', backend_version='0.10.2', category='message', data={'Reply-To': '<steve@viens.net>', 'X-MSMail-Priority': 'Normal', 'List-Post': '<mailto:juddi-dev@ws.apache.org>', 'X-MimeOLE': 'Produced By Microsoft MimeOLE V6.00.2900.2527', 'Message-ID': '<003001c5676d$8fdf9d20$6401a8c0@INSPIRON>', 'body': '{plain=jUDDI (in cvs) has been updated with Axis 1.2 final and I plan to stick\\nto the original plan that we voted on which is releasing a 0.9rc4 in a\\nday or two and a 0.9 final within two weeks ... I\\'ll use the two weeks\\nto update jUDDI documentation.\\n \\nSteve\\n, html=<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.0 Transitional//EN\">\\n<HTML><HEAD>\\n<META HTTP-EQUIV=\"Content-Type\" CONTENT=\"text/html; charset=us-ascii\">\\n<TITLE>Message</TITLE>\\n\\n<META content=\"MSHTML 6.00.2900.2627\" name=GENERATOR></HEAD>\\n<BODY>\\n<DIV><FONT face=Arial size=2><SPAN class=894221712-02062005>jUDDI (in cvs) has \\nbeen updated with Axis 1.2 final and I plan to stick to the original plan that \\nwe voted on which is releasing a 0.9rc4 in a day or two and a 0.9 final within \\ntwo weeks ... I\\'ll use the two weeks to update jUDDI \\ndocumentation.</SPAN></FONT></DIV>\\n<DIV><FONT face=Arial size=2><SPAN \\nclass=894221712-02062005></SPAN></FONT>&nbsp;</DIV>\\n<DIV><FONT face=Arial size=2><SPAN \\nclass=894221712-02062005>Steve</SPAN></FONT></DIV></BODY></HTML>\\n}', 'Received-SPF': 'neutral (hermes.apache.org: local policy)', 'Importance': 'Normal', 'list-help': '<mailto:juddi-dev-help@ws.apache.org>', 'X-Mailer': 'Microsoft Outlook, Build 10.0.2627', 'To': '<juddi-dev@ws.apache.org>', 'X-Virus-Checked': 'Checked', 'Mailing-List': 'contact juddi-dev-help@ws.apache.org; run by ezmlm', 'Content-Type': 'multipart/alternative;\\n\\tboundary=\"----=_NextPart_000_0031_01C5674C.08CDFD20\"', 'X-Spam-Rating': 'minotaur.apache.org 1.6.2 0/1000/N', 'Return-Path': '<juddi-dev-return-942-apmail-ws-juddi-dev-archive=ws.apache.org@ws.apache.org>', 'list-unsubscribe': '<mailto:juddi-dev-unsubscribe@ws.apache.org>', 'Received': 'from inspiron (c-24-128-68-179.hsd1.nh.comcast.net[24.128.68.179])\\n          by comcast.net (sccrmhc12) with SMTP\\n          id <20050602122123012000qtt7e>; Thu, 2 Jun 2005 12:21:23 +0000', 'From': '\"Steve Viens\" <steve@viens.net>', 'Date': 'Thu, 2 Jun 2005 08:21:05 -0400', 'MIME-Version': '1.0', 'Subject': 'jUDDI updated with Axis 1.2 final', 'X-Spam-Check-By': 'apache.org', 'X-Priority': '3 (Normal)', 'Delivered-To': 'mailing list juddi-dev@ws.apache.org', 'List-Id': '<juddi-dev.ws.apache.org>', 'Precedence': 'bulk', 'unixfrom': 'juddi-dev-return-942-apmail-ws-juddi-dev-archive=ws.apache.org@ws.apache.org Thu Jun 02 12:21:44 2005', 'X-ASF-Spam-Status': 'No, hits=0.0 required=10.0\\n\\ttests=HTML_60_70,HTML_MESSAGE'}, origin='http://mail-archives.apache.org/mod_mbox/juddi-dev', perceval_version='0.11.2', tag='http://mail-archives.apache.org/mod_mbox/juddi-dev', timestamp=1533685140.170142, updated_on=1117714865.0, uuid='9fb9a57324ec482149ec09fd6922b5f32f4d90b7')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "mailing_list_posts_mbox_df = mailing_list_posts_mbox_df_raw.select(\n",
    "    \"*\",\n",
    "    mailing_list_posts_mbox_df_raw.data.getField(\"From\").alias(\"from\"),\n",
    "    extract_email(mailing_list_posts_mbox_df_raw.data.getField(\"From\")).alias(\"from_processed_email\"),\n",
    "    mailing_list_posts_mbox_df_raw.data.getField(\"body\").alias(\"body\"),\n",
    "    mailing_list_posts_mbox_df_raw.data.getField(\"Message-ID\").alias(\"message_id\"),\n",
    "    mailing_list_posts_mbox_df_raw.data.getField(\"In-Reply-To\").alias(\"in_reply_to\"),\n",
    "    mailing_list_posts_mbox_df_raw.data.getField(\"Content-Language\").alias(\"content_language\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reusing\n"
     ]
    }
   ],
   "source": [
    "mailing_list_posts_mbox_df_saved = non_blocking_df_save_or_load(\n",
    "    mailing_list_posts_mbox_df,\n",
    "    \"{0}/processed_mbox_data_4\".format(fs_prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_sentiment_df = mailing_list_posts_mbox_df_saved.select(\"project_name\", lookup_sentiment_udf(\"body\").alias(\"sentiment\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reusing\n"
     ]
    }
   ],
   "source": [
    "post_sentiment_df_saved = non_blocking_df_save_or_load(\n",
    "    post_sentiment_df,\n",
    "    \"{0}/post_sentiment_df_1\".format(fs_prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_post_sentiment = post_sentiment_df_saved.groupBy(\"project_name\").agg(\n",
    "    F.max(\"sentiment.neg\").alias(\"sentiment.neg_max\"),\n",
    "    F.avg(\"sentiment.neg\").alias(\"sentiment.neg_avg\"), F.expr('percentile_approx(sentiment.neg, array(0.25, 0.5, 0.75))').alias(\"neg_quantiles\"),\n",
    "    F.max(\"sentiment.pos\").alias(\"sentiment.pos_max\"), F.avg(\"sentiment.pos\").alias(\"sentiment.pos_avg\"), F.expr('percentile_approx(sentiment.neg, array(0.25, 0.5, 0.75))').alias(\"pos_quantiles\"),\n",
    ").select(\n",
    "    \"*\",\n",
    "    F.col(\"project_name\").alias(\"project\"),\n",
    "    F.expr(\"neg_quantiles[0]\").alias(\"sentiment.neg_25quantile\"),\n",
    "    F.expr(\"neg_quantiles[1]\").alias(\"sentiment.neg_50quantile\"),\n",
    "    F.expr(\"neg_quantiles[2]\").alias(\"sentiment.neg_75quantile\"),\n",
    "    F.expr(\"pos_quantiles[0]\").alias(\"sentiment.pos_25quantile\"),\n",
    "    F.expr(\"pos_quantiles[1]\").alias(\"sentiment.pos_50quantile\"),\n",
    "    F.expr(\"pos_quantiles[2]\").alias(\"sentiment.pos_75quantile\")).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------------+--------------------+--------------------+-----------------+-------------------+--------------------+------------+------------------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "|project_name|sentiment.neg_max|   sentiment.neg_avg|       neg_quantiles|sentiment.pos_max|  sentiment.pos_avg|       pos_quantiles|     project|sentiment.neg_25quantile|sentiment.neg_50quantile|sentiment.neg_75quantile|sentiment.pos_25quantile|sentiment.pos_50quantile|sentiment.pos_75quantile|\n",
      "+------------+-----------------+--------------------+--------------------+-----------------+-------------------+--------------------+------------+------------------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "|      roller|            0.192| 0.03653448275862067|[0.009, 0.026, 0....|            0.297|0.08503940886699507|[0.009, 0.026, 0....|      roller|                   0.009|                   0.026|                   0.053|                   0.009|                   0.026|                   0.053|\n",
      "|       twill|            0.148| 0.02367897727272727|  [0.0, 0.02, 0.035]|            0.337|0.06119744318181825|  [0.0, 0.02, 0.035]|       twill|                     0.0|                    0.02|                   0.035|                     0.0|                    0.02|                   0.035|\n",
      "|    marmotta|            0.249|0.030172535211267552| [0.0, 0.023, 0.045]|            0.294|0.07125704225352113| [0.0, 0.023, 0.045]|    marmotta|                     0.0|                   0.023|                   0.045|                     0.0|                   0.023|                   0.045|\n",
      "|       shiro|            0.221|0.026898450946643684| [0.0, 0.021, 0.037]|            0.437|0.08386574870912221| [0.0, 0.021, 0.037]|       shiro|                     0.0|                   0.021|                   0.037|                     0.0|                   0.021|                   0.037|\n",
      "|       eagle|            0.141|0.021073170731707325| [0.0, 0.014, 0.031]|            0.197|0.07302439024390245| [0.0, 0.014, 0.031]|       eagle|                     0.0|                   0.014|                   0.031|                     0.0|                   0.014|                   0.031|\n",
      "|       hbase|            0.336|0.047520055452864765| [0.0, 0.029, 0.058]|            0.419| 0.0648682994454709| [0.0, 0.029, 0.058]|       hbase|                     0.0|                   0.029|                   0.058|                     0.0|                   0.029|                   0.058|\n",
      "|  cloudstack|            0.374|0.030660410167236668|[0.011, 0.027, 0.04]|            0.416|0.07643164731754547|[0.011, 0.027, 0.04]|  cloudstack|                   0.011|                   0.027|                    0.04|                   0.011|                   0.027|                    0.04|\n",
      "|       juddi|            0.302| 0.04106702898550722| [0.0, 0.023, 0.054]|            0.192|0.05783514492753621| [0.0, 0.023, 0.054]|       juddi|                     0.0|                   0.023|                   0.054|                     0.0|                   0.023|                   0.054|\n",
      "|       spark|            0.297|0.029928716020821203|[0.006, 0.023, 0....|            0.503|0.08106636784268348|[0.006, 0.023, 0....|       spark|                   0.006|                   0.023|                   0.297|                   0.006|                   0.023|                   0.297|\n",
      "|     phoenix|            0.278|  0.0286186250280833| [0.0, 0.019, 0.278]|            0.604|0.06938373399236117| [0.0, 0.019, 0.278]|     phoenix|                     0.0|                   0.019|                   0.278|                     0.0|                   0.019|                   0.278|\n",
      "|        bval|            0.129| 0.03530769230769231|[0.005, 0.02, 0.066]|            0.308|0.09284615384615381|[0.005, 0.02, 0.066]|        bval|                   0.005|                    0.02|                   0.066|                   0.005|                    0.02|                   0.066|\n",
      "|       maven|            0.258|0.027266794319451174|  [0.0, 0.02, 0.042]|            0.405|0.05773400351045161|  [0.0, 0.02, 0.042]|       maven|                     0.0|                    0.02|                   0.042|                     0.0|                    0.02|                   0.042|\n",
      "|openmeetings|            0.355| 0.03206666666666668|[0.011, 0.026, 0....|            0.351|0.06567819548872181|[0.011, 0.026, 0....|openmeetings|                   0.011|                   0.026|                   0.043|                   0.011|                   0.026|                   0.043|\n",
      "|         poi|             0.44|0.026662299239222347|  [0.0, 0.02, 0.039]|            0.473|0.09284953508030437|  [0.0, 0.02, 0.039]|         poi|                     0.0|                    0.02|                   0.039|                     0.0|                    0.02|                   0.039|\n",
      "|        hive|            0.299|0.031159021113243708| [0.0, 0.022, 0.048]|            0.744| 0.0713851247600767| [0.0, 0.022, 0.048]|        hive|                     0.0|                   0.022|                   0.048|                     0.0|                   0.022|                   0.048|\n",
      "+------------+-----------------+--------------------+--------------------+-----------------+-------------------+--------------------+------------+------------------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "agg_post_sentiment.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(username,StringType,false),StructField(extra,StructType(List(StructField(name,StringType,true),StructField(key_fingerprints,ArrayType(StringType,true),true),StructField(urls,ArrayType(StringType,true),true))),true),StructField(projects,ArrayType(StringType,true),true)))"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apache_people_df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(project_name,StringType,true),StructField(box_type,StringType,true),StructField(mbox_id,StringType,true),StructField(backend_name,StringType,true),StructField(backend_version,StringType,true),StructField(category,StringType,true),StructField(data,MapType(StringType,StringType,true),true),StructField(origin,StringType,true),StructField(perceval_version,StringType,true),StructField(tag,StringType,true),StructField(timestamp,DoubleType,true),StructField(updated_on,DoubleType,true),StructField(uuid,StringType,true),StructField(from,StringType,true),StructField(from_processed_email,StringType,true),StructField(body,StringType,true),StructField(message_id,StringType,true),StructField(in_reply_to,StringType,true),StructField(content_language,StringType,true)))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mailing_list_posts_mbox_df_saved.schema"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Find committers welcome e-mail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apache_people_df.join(mailing_list_posts_mbox_df_saved,\n",
    "#                     join_conditions(F.instr(mailing_list_posts_mbox_df_saved)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start using some of the lazily created DFs to compute the sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15440"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authors_grouped_by_id_saved.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+--------------------+--------------------+---------------+-------------+\n",
      "|project_name|       new_unique_id|              emails|              Author|github_username|latest_commit|\n",
      "+------------+--------------------+--------------------+--------------------+---------------+-------------+\n",
      "|    accumulo|  <dhutchis@mit.edu>|[<dhutchis@mit.edu>]|Dylan Hutchison <...|               |   2015-01-02|\n",
      "|    accumulo|<mario.pastorelli...|[<mario.pastorell...|Mario Pastorelli ...|               |   2015-12-30|\n",
      "|    activemq|<czobrisky@gmail....|[<czobrisky@gmail...|Chad Zobrisky <cz...|               |   2014-12-31|\n",
      "|       arrow|<adeneche@dremio....|[<adeneche@dremio...|adeneche <adenech...|               |   2017-01-06|\n",
      "|       atlas|<amestry@apache.org>|[<amestry@apache....|Ashutosh Mestry <...|               |   2017-01-06|\n",
      "|       atlas|<venkat@hortonwor...|[<venkat@hortonwo...|Venkat Ranganatha...|               |   2015-01-02|\n",
      "|      aurora|<ndonatucci@medal...|[<ndonatucci@meda...|Nicolás Donatucci...|               |   2017-01-03|\n",
      "|      aurora|<sgeorge@twitter....|[<sgeorge@twitter...|Selvin George <sg...|               |   2013-01-05|\n",
      "|        beam|<cpovirk@google.com>|[<cpovirk@google....|cpovirk <cpovirk@...|               |   2016-01-01|\n",
      "|        beam|<p.kaczmarczyk@oc...|[<p.kaczmarczyk@o...|Pawel Kaczmarczyk...|               |   2018-01-02|\n",
      "|      bigtop|<pengwenwu2008@16...|[<pengwenwu2008@1...|Wenwu Peng <pengw...|               |   2014-01-02|\n",
      "|    brooklyn|  <bostko@gmail.com>|[<bostko@gmail.com>]|Valentin Aitken <...|               |   2014-12-30|\n",
      "|     calcite|<serhii.harnyk@gm...|[<serhii.harnyk@g...|Serhii-Harnyk <se...|               |   2015-12-29|\n",
      "|       camel|<Thomas.papke@icw...|[<Thomas.papke@ic...|Thopap <Thomas.pa...|               |   2017-01-03|\n",
      "|       camel|<jvazquez@tecsisa...|[<jvazquez@tecsis...|juanjovazquez <jv...|               |   2014-01-01|\n",
      "|       camel|             nkukhar|[<kukhar.n@gmail....|nkukhar <kukhar.n...|        nkukhar|   2015-01-02|\n",
      "|       camel|        softwaredoug|[<dturnbull@o19s....|Doug Turnbull <dt...|   softwaredoug|   2014-01-04|\n",
      "|  carbondata|<SRIGOPALMOHANTY@...|[<SRIGOPALMOHANTY...|SRIGOPALMOHANTY <...|               |   2017-01-03|\n",
      "|  carbondata|<vincent.chenfei@...|[<vincent.chenfei...|vincentchenfei <v...|               |   2017-01-03|\n",
      "|   cassandra|<MWeiser@ardmoref...|[<MWeiser@ardmore...|Matthias Weiser <...|               |   2018-01-02|\n",
      "+------------+--------------------+--------------------+--------------------+---------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "authors_grouped_by_id_saved.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------+\n",
      "| project_name|author_count|\n",
      "+-------------+------------+\n",
      "|         lucy|          14|\n",
      "|      vxquery|          16|\n",
      "|    chemistry|          12|\n",
      "|       roller|          19|\n",
      "|        geode|         136|\n",
      "|       falcon|          55|\n",
      "|trafficserver|         307|\n",
      "|          tez|          26|\n",
      "|       pdfbox|          21|\n",
      "|        httpd|         113|\n",
      "|   carbondata|         135|\n",
      "|        celix|          13|\n",
      "|     accumulo|          95|\n",
      "|       wicket|          98|\n",
      "|   servicemix|          19|\n",
      "|        twill|          38|\n",
      "|     clerezza|          17|\n",
      "|      couchdb|         169|\n",
      "|       bigtop|         139|\n",
      "|     marmotta|          25|\n",
      "+-------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_authors_by_project = authors_grouped_by_id_saved.groupBy(\"project_name\").agg(F.count(\"Author\").alias(\"author_count\"))\n",
    "num_authors_by_project.cache()\n",
    "num_authors_by_project.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the sample %s for each project so we can get reasonable confidence bounds for sampling.\n",
    "Looking at http://veekaybee.github.io/2015/08/04/how-big-of-a-sample-size-do-you-need/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I think is Cochran's formula scaled for small datasets\n",
    "@F.udf(IntegerType())\n",
    "def compute_num_required_sample_1(pop_size):\n",
    "    import numpy as np\n",
    "    import scipy.stats\n",
    "    import math\n",
    "    e = 0.05\n",
    "    Z = 1.64 # 90%, 95%: 1.96\n",
    "    p = 0.5\n",
    "    N = pop_size\n",
    "    # CALC SAMPLE SIZE\n",
    "    n_0 = ((Z**2) * p * (1-p)) / (e**2)\n",
    "    # ADJUST SAMPLE SIZE FOR FINITE POPULATION\n",
    "    n = n_0 / (1 + ((n_0 - 1) / float(N)) )\n",
    "    target = int(math.ceil(n))\n",
    "    # Compute a fall back size\n",
    "    fall_back_size = min(3, pop_size)\n",
    "    return max(fall_back_size, target) # THE SAMPLE SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "399.99999999999994"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number 2: https://en.wikipedia.org/wiki/Sample_size_determination#Estimation\n",
    "def walds_method():\n",
    "    return 1/(0.05**2) # +- 5%\n",
    "walds_method()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_sample_sizes = num_authors_by_project.withColumn(\n",
    "    \"sample_size_1\",\n",
    "    compute_num_required_sample_1(\"author_count\")).persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reusing\n"
     ]
    }
   ],
   "source": [
    "sample_sizes = non_blocking_df_save_or_load(\n",
    "    raw_sample_sizes,\n",
    "    \"{0}/sample_sizes_10\".format(fs_prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+-------------+\n",
      "|project_name|author_count|sample_size_1|\n",
      "+------------+------------+-------------+\n",
      "|spamassassin|          39|           35|\n",
      "|        oodt|          41|           36|\n",
      "|     cayenne|          45|           39|\n",
      "|     streams|          25|           23|\n",
      "|  jackrabbit|          37|           33|\n",
      "|  manifoldcf|          19|           18|\n",
      "|        drat|          29|           27|\n",
      "|      giraph|          37|           33|\n",
      "|     cordova|           1|            1|\n",
      "|      thrift|         237|          127|\n",
      "|      tomcat|          34|           31|\n",
      "|     syncope|          31|           28|\n",
      "|     calcite|         159|          101|\n",
      "|      impala|         131|           89|\n",
      "|       nutch|          72|           57|\n",
      "|    activemq|          90|           68|\n",
      "|  deltaspike|          56|           47|\n",
      "|      allura|          84|           65|\n",
      "|openmeetings|           7|            7|\n",
      "|       tomee|          47|           41|\n",
      "+------------+------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_sizes.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|sum(sample_size_1)|\n",
      "+------------------+\n",
      "|              9117|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_sizes.groupby().agg(F.sum(\"sample_size_1\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this is a bit high to do on a shoestring budget with sampling, but what about if we limit to folks who have recently participated & got rid of projects with limited or no recent participation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(project_name,StringType,true),StructField(new_unique_id,StringType,true),StructField(emails,ArrayType(StringType,true),true),StructField(Author,StringType,true),StructField(github_username,StringType,true),StructField(latest_commit,DateType,true)))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authors_grouped_by_id_saved.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_distinct_authors_latest_commit = authors_grouped_by_id_saved.filter(\n",
    "    (F.date_sub(F.current_date(), 365)) < authors_grouped_by_id_saved.latest_commit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(project_name,StringType,true),StructField(new_unique_id,StringType,true),StructField(emails,ArrayType(StringType,true),true),StructField(Author,StringType,true),StructField(github_username,StringType,true),StructField(latest_commit,DateType,true)))"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "active_distinct_authors_latest_commit.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+--------------------+--------------------+---------------+-------------+\n",
      "|project_name|       new_unique_id|              emails|              Author|github_username|latest_commit|\n",
      "+------------+--------------------+--------------------+--------------------+---------------+-------------+\n",
      "|        beam|<p.kaczmarczyk@oc...|[<p.kaczmarczyk@o...|Pawel Kaczmarczyk...|               |   2018-01-02|\n",
      "|   cassandra|<MWeiser@ardmoref...|[<MWeiser@ardmore...|Matthias Weiser <...|               |   2018-01-02|\n",
      "|         cxf|<butkovic@gmail.com>|[<butkovic@gmail....|Peter Butkovic <b...|               |   2017-12-31|\n",
      "|         cxf|<simon.marti@inve...|[<simon.marti@inv...|Simon Marti <simo...|               |   2017-12-31|\n",
      "|       eagle| <yonzhang@ebay.com>|[<yonzhang@ebay.c...|yonzhang <yonzhan...|               |   2018-01-02|\n",
      "|        hive| <ganu.ec@gmail.com>|[<ganu.ec@gmail.c...|Ganesha Shreedhar...|               |   2018-01-05|\n",
      "|       karaf| <ancosen@gmail.com>|[<ancosen@gmail.c...|Andrea Cosentino ...|               |   2018-01-04|\n",
      "|        kudu|<wdberkeley@apach...|[<wdberkeley@apac...|Will Berkeley <wd...|               |   2018-01-06|\n",
      "|       nutch|<bvachon@attivio....|[<bvachon@attivio...|Ben Vachon <bvach...|               |   2018-01-05|\n",
      "|    systemml|             mboehm7|[<mboehm7@gmail.c...|Matthias Boehm <m...|        mboehm7|   2018-01-06|\n",
      "|       tomee|             AndyGee|[<agumbrecht@tomi...|Andy Gumbrecht <a...|        AndyGee|   2018-01-01|\n",
      "|    zeppelin|<simonmueller@liv...|[<simonmueller@li...|skymon <simonmuel...|               |   2018-01-05|\n",
      "|       karaf|              MrEasy|[<r.neubauer@seeb...|Rico Neubauer <r....|         MrEasy|   2017-12-31|\n",
      "|       arrow|<brian.hulette@cc...|[<brian.hulette@c...|Brian Hulette <br...|               |   2018-01-05|\n",
      "|       camel|           davsclaus|[<claus.ibsen@gma...|Claus Ibsen <clau...|      davsclaus|   2018-01-06|\n",
      "|  cloudstack|<the.evergreen@gm...|[<the.evergreen@g...|Frank Maximus <th...|               |   2018-01-05|\n",
      "|        fluo|<furkankamaci@gma...|[<furkankamaci@gm...|Furkan KAMACI <fu...|               |   2018-01-02|\n",
      "|      hadoop| <epayne@apache.org>|[<epayne@apache.o...|Eric Payne <epayn...|               |   2018-01-05|\n",
      "|        kudu|<anjuwong@g.ucla....|[<anjuwong@g.ucla...|Andrew Wong <anju...|               |   2018-01-04|\n",
      "|        kudu|<sailesh@apache.org>|[<sailesh@apache....|Sailesh Mukil <sa...|               |   2018-01-04|\n",
      "+------------+--------------------+--------------------+--------------------+---------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "2240\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(project_name='beam', new_unique_id='<p.kaczmarczyk@ocado.com>', emails=['<p.kaczmarczyk@ocado.com>'], Author='Pawel Kaczmarczyk <p.kaczmarczyk@ocado.com>', github_username='', latest_commit=datetime.date(2018, 1, 2)),\n",
       " Row(project_name='cassandra', new_unique_id='<MWeiser@ardmorefinancial.com>', emails=['<MWeiser@ardmorefinancial.com>'], Author='Matthias Weiser <MWeiser@ardmorefinancial.com>', github_username='', latest_commit=datetime.date(2018, 1, 2)),\n",
       " Row(project_name='cxf', new_unique_id='<butkovic@gmail.com>', emails=['<butkovic@gmail.com>'], Author='Peter Butkovic <butkovic@gmail.com>', github_username='', latest_commit=datetime.date(2017, 12, 31)),\n",
       " Row(project_name='cxf', new_unique_id='<simon.marti@inventage.com>', emails=['<simon.marti@inventage.com>'], Author='Simon Marti <simon.marti@inventage.com>', github_username='', latest_commit=datetime.date(2017, 12, 31)),\n",
       " Row(project_name='eagle', new_unique_id='<yonzhang@ebay.com>', emails=['<yonzhang@ebay.com>'], Author='yonzhang <yonzhang@ebay.com>', github_username='', latest_commit=datetime.date(2018, 1, 2))]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "active_distinct_authors_latest_commit.show()\n",
    "print(active_distinct_authors_latest_commit.count())\n",
    "active_distinct_authors_latest_commit.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------+\n",
      "| project_name|author_count|\n",
      "+-------------+------------+\n",
      "|         lucy|           2|\n",
      "|       roller|           1|\n",
      "|        geode|          47|\n",
      "|       falcon|           4|\n",
      "|trafficserver|          35|\n",
      "|          tez|           6|\n",
      "|       pdfbox|           4|\n",
      "|        httpd|          14|\n",
      "|   carbondata|          33|\n",
      "|        celix|           6|\n",
      "|       wicket|          14|\n",
      "|     accumulo|          12|\n",
      "|        twill|           2|\n",
      "|      couchdb|          22|\n",
      "|       bigtop|          12|\n",
      "|     marmotta|           2|\n",
      "|          vcl|           1|\n",
      "|   freemarker|           4|\n",
      "|       buildr|           2|\n",
      "|        shiro|           2|\n",
      "+-------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "active_num_authors_by_project = active_distinct_authors_latest_commit.groupBy(\"project_name\").agg(F.count(\"Author\").alias(\"author_count\"))\n",
    "active_num_authors_by_project.cache()\n",
    "active_num_authors_by_project.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_raw_sample_sizes = active_num_authors_by_project.withColumn(\n",
    "    \"sample_size_1\",\n",
    "    compute_num_required_sample_1(\"author_count\")).persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reusing\n"
     ]
    }
   ],
   "source": [
    "active_sample_sizes = non_blocking_df_save_or_load_csv(\n",
    "    active_raw_sample_sizes,\n",
    "    \"{0}/active_sample_sizes_13\".format(fs_prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_active_sample_sizes = active_sample_sizes.filter(\n",
    "    active_sample_sizes.sample_size_1 > 10).persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|sum(sample_size_1)|\n",
      "+------------------+\n",
      "|              1605|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filtered_active_sample_sizes.groupby().agg(F.sum(\"sample_size_1\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's probably ok, lets go ahead and compute the sample set for each project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_fractions = filtered_active_sample_sizes.withColumn(\n",
    "    \"sample_fraction\",\n",
    "    (filtered_active_sample_sizes.sample_size_1+0.5) / filtered_active_sample_sizes.author_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_sample_fractions = sample_fractions.select(\n",
    "    sample_fractions.project_name, sample_fractions.sample_fraction).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(project_name='impala', sample_fraction=0.8928571428571429),\n",
       " Row(project_name='calcite', sample_fraction=0.9782608695652174),\n",
       " Row(project_name='nutch', sample_fraction=1.03125),\n",
       " Row(project_name='thrift', sample_fraction=0.9482758620689655),\n",
       " Row(project_name='drill', sample_fraction=0.94),\n",
       " Row(project_name='trafficserver', sample_fraction=0.9285714285714286),\n",
       " Row(project_name='accumulo', sample_fraction=1.0416666666666667),\n",
       " Row(project_name='wicket', sample_fraction=1.0357142857142858),\n",
       " Row(project_name='subversion', sample_fraction=1.0357142857142858),\n",
       " Row(project_name='groovy', sample_fraction=1.0416666666666667),\n",
       " Row(project_name='phoenix', sample_fraction=0.9782608695652174),\n",
       " Row(project_name='storm', sample_fraction=0.95),\n",
       " Row(project_name='airavata', sample_fraction=0.9782608695652174),\n",
       " Row(project_name='asterixdb', sample_fraction=1.0416666666666667),\n",
       " Row(project_name='zeppelin', sample_fraction=0.9761904761904762),\n",
       " Row(project_name='ignite', sample_fraction=0.7611111111111111),\n",
       " Row(project_name='camel', sample_fraction=0.823076923076923),\n",
       " Row(project_name='arrow', sample_fraction=0.87),\n",
       " Row(project_name='beam', sample_fraction=0.75),\n",
       " Row(project_name='metron', sample_fraction=1.0357142857142858),\n",
       " Row(project_name='geode', sample_fraction=0.8829787234042553),\n",
       " Row(project_name='spark', sample_fraction=0.7008196721311475),\n",
       " Row(project_name='ranger', sample_fraction=0.975),\n",
       " Row(project_name='tika', sample_fraction=1.0454545454545454),\n",
       " Row(project_name='kylin', sample_fraction=0.9054054054054054),\n",
       " Row(project_name='ambari', sample_fraction=0.7911392405063291),\n",
       " Row(project_name='samza', sample_fraction=0.9772727272727273),\n",
       " Row(project_name='carbondata', sample_fraction=0.9242424242424242),\n",
       " Row(project_name='bookkeeper', sample_fraction=0.94),\n",
       " Row(project_name='cloudstack', sample_fraction=0.9027777777777778),\n",
       " Row(project_name='zookeeper', sample_fraction=1.0384615384615385),\n",
       " Row(project_name='tinkerpop', sample_fraction=1.03125),\n",
       " Row(project_name='trafodion', sample_fraction=0.9444444444444444),\n",
       " Row(project_name='cassandra', sample_fraction=0.875),\n",
       " Row(project_name='libcloud', sample_fraction=0.9772727272727273),\n",
       " Row(project_name='notebook', sample_fraction=0.9242424242424242),\n",
       " Row(project_name='couchdb', sample_fraction=0.9772727272727273),\n",
       " Row(project_name='nteract', sample_fraction=0.9722222222222222),\n",
       " Row(project_name='bigtop', sample_fraction=1.0416666666666667),\n",
       " Row(project_name='struts', sample_fraction=1.0454545454545454),\n",
       " Row(project_name='hadoop', sample_fraction=0.764367816091954),\n",
       " Row(project_name='httpd', sample_fraction=1.0357142857142858),\n",
       " Row(project_name='hbase', sample_fraction=0.8188405797101449),\n",
       " Row(project_name='kafka', sample_fraction=0.7526315789473684),\n",
       " Row(project_name='karaf', sample_fraction=1.0294117647058822),\n",
       " Row(project_name='atlas', sample_fraction=1.0357142857142858),\n",
       " Row(project_name='flink', sample_fraction=0.823076923076923),\n",
       " Row(project_name='mesos', sample_fraction=0.8557692307692307),\n",
       " Row(project_name='kudu', sample_fraction=0.9791666666666666),\n",
       " Row(project_name='nifi', sample_fraction=0.8777777777777778),\n",
       " Row(project_name='hive', sample_fraction=0.8584905660377359),\n",
       " Row(project_name='cxf', sample_fraction=0.9482758620689655),\n",
       " Row(project_name='orc', sample_fraction=1.0357142857142858)]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_sample_fractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_authors = active_distinct_authors_latest_commit.sampleBy(\n",
    "    \"project_name\",\n",
    "    fractions=dict(map(lambda r: (r[0], min(1.0, r[1])), local_sample_fractions)),\n",
    "    seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reusing\n"
     ]
    }
   ],
   "source": [
    "sampled_authors_saved = non_blocking_df_save_or_load(\n",
    "    sampled_authors, \"{0}/sampled_authors_6\".format(fs_prefix)).alias(\"sampled_authors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+--------------------+--------------------+---------------+-------------+\n",
      "|project_name|       new_unique_id|              emails|              Author|github_username|latest_commit|\n",
      "+------------+--------------------+--------------------+--------------------+---------------+-------------+\n",
      "|      ambari|<adoroszlai@apach...|[<adoroszlai@apac...|Doroszlai, Attila...|               |   2018-01-05|\n",
      "|       arrow|           JinHai-CN|[<haijin.chn@gmai...|Jin Hai <haijin.c...|      JinHai-CN|   2018-01-03|\n",
      "|     calcite|<maryann.xue@gmai...|[<maryann.xue@gma...|maryannxue <marya...|               |   2018-01-04|\n",
      "|       camel|             gautric|[<gautric@redhat....|gautric <gautric@...|        gautric|   2017-12-31|\n",
      "|  carbondata|<praveenmeenakshi...|[<praveenmeenaksh...|praveenmeenakshi5...|               |   2018-01-04|\n",
      "|  cloudstack|<372575+khos2ow@u...|[<372575+khos2ow@...|Khosrow Moossavi ...|               |   2018-01-02|\n",
      "|     couchdb|<alexander@spotme...|[<alexander@spotm...|AlexanderKarabero...|               |   2018-01-05|\n",
      "|      groovy|<jwagenleitner@ap...|[<jwagenleitner@a...|John Wagenleitner...|               |   2018-01-01|\n",
      "|      ignite|<ilantukh@gridgai...|[<ilantukh@gridga...|Ilya Lantukh <ila...|               |   2018-01-05|\n",
      "|      ignite|<pivanov@gridgain...|[<pivanov@gridgai...|Ivanov Petr <piva...|               |   2018-01-03|\n",
      "|      impala|<dknupp@cloudera....|[<dknupp@cloudera...|David Knupp <dknu...|               |   2018-01-05|\n",
      "|       karaf|    <fpa@openrun.re>|  [<fpa@openrun.re>]|Francois Papon <f...|               |   2018-01-05|\n",
      "|       kylin|    <ganma@ebay.com>|  [<ganma@ebay.com>]|Ma,Gang <ganma@eb...|               |   2018-01-03|\n",
      "|        nifi| <bbende@apache.org>|[<bbende@apache.o...|Bryan Bende <bben...|               |   2018-01-05|\n",
      "|       samza|<tstumpges@ntent....|[<tstumpges@ntent...|thunderstumpges <...|               |   2018-01-01|\n",
      "|      struts|<zalsaeed@cs.uore...|[<zalsaeed@cs.uor...|zalsaeed <zalsaee...|               |   2018-01-01|\n",
      "|        tika|<nassif.lfcn@dpf....|[<nassif.lfcn@dpf...|Nassif <nassif.lf...|               |   2018-01-04|\n",
      "|      ambari|<vsuvagia@hortonw...|[<vsuvagia@horton...|Vishal Suvagia <v...|               |   2018-01-05|\n",
      "|        beam|<alan@Alans-MacBo...|[<alan@Alans-MacB...|Alan Myrvold <ala...|               |   2018-01-03|\n",
      "|        beam|<petr.shevtsov@gm...|[<petr.shevtsov@g...|Petr Shevtsov <pe...|               |   2018-01-05|\n",
      "+------------+--------------------+--------------------+--------------------+---------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sampled_authors_saved.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1591"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_authors_saved.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(project_name,StringType,true),StructField(new_unique_id,StringType,true),StructField(emails,ArrayType(StringType,true),true),StructField(Author,StringType,true),StructField(github_username,StringType,true),StructField(latest_commit,DateType,true)))"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_authors_saved.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_authors_grouped_by_author_id = sampled_authors_saved.groupBy(\n",
    "    sampled_authors_saved.new_unique_id).agg(\n",
    "    F.collect_set(sampled_authors_saved.project_name).alias(\"projects\"),\n",
    "    F.first(sampled_authors_saved.emails).alias(\"emails\"),\n",
    "    F.first(sampled_authors_saved.Author).alias(\"Author\"),\n",
    "    F.first(sampled_authors_saved.github_username).alias(\"github_username\"))\n",
    "sampled_authors_grouped_by_author_id_flattened = sampled_authors_grouped_by_author_id.select(\n",
    "    \"new_unique_id\",\n",
    "    F.concat_ws(' ', sampled_authors_grouped_by_author_id.projects).alias(\"projects\"),\n",
    "    \"emails\",\n",
    "    \"Author\",\n",
    "    \"github_username\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+--------------------+--------------------+---------------+\n",
      "|       new_unique_id|    projects|              emails|              Author|github_username|\n",
      "+--------------------+------------+--------------------+--------------------+---------------+\n",
      "|<yuzhong.yz@aliba...|     calcite|[<yuzhong.yz@alib...|yuzhong <yuzhong....|               |\n",
      "|<vandana.yadav759...|  carbondata|[<vandana.yadav75...|vandana <vandana....|               |\n",
      "|<vozerov@gridgain...|      ignite|[<vozerov@gridgai...|devozerov <vozero...|               |\n",
      "|<jcustenborder@gm...|       kafka|[<jcustenborder@g...|Jeremy Custenbord...|               |\n",
      "| <jdeppe@pivotal.io>|       geode|[<jdeppe@pivotal....|Jens Deppe <jdepp...|               |\n",
      "|<30875507+ashwini...|   tinkerpop|[<30875507+ashwin...|Ashwini Singh <30...|               |\n",
      "|              yew1eb|       flink|[<yew1eb@gmail.com>]|yew1eb <yew1eb@gm...|         yew1eb|\n",
      "| <b.lerer@gmail.com>|   cassandra|[<b.lerer@gmail.c...|Benjamin Lerer <b...|               |\n",
      "|<ehsan.totoni@int...|       arrow|[<ehsan.totoni@in...|Ehsan Totoni <ehs...|               |\n",
      "|          anoopsjohn|       hbase|[<anoopsamjohn@gm...|anoopsamjohn <ano...|     anoopsjohn|\n",
      "|<zhaijia@apache.org>|  bookkeeper|[<zhaijia@apache....|Jia Zhai <zhaijia...|               |\n",
      "|<progers@maprtech...|       drill|[<progers@maprtec...|Paul Rogers <prog...|               |\n",
      "|<lizhou.gao@zilli...|       arrow|[<lizhou.gao@zill...|Lizhou Gao <lizho...|               |\n",
      "|<rrussell@adobe.com>|       arrow|[<rrussell@adobe....|rrussell <rrussel...|               |\n",
      "|<cchampeau@apache...|      groovy|[<cchampeau@apach...|Cedric Champeau <...|               |\n",
      "|           ArnaudFnr|        beam|[<arnaudfournier9...|Arnaud <arnaudfou...|      ArnaudFnr|\n",
      "|               PnPie|       kafka|[<yu.liu003@gmail...|Yu <yu.liu003@gma...|          PnPie|\n",
      "|<cao.xuewen@zte.c...|       spark|[<cao.xuewen@zte....|caoxuewen <cao.xu...|               |\n",
      "|             bgaborg|hbase hadoop|[<gabor.bota@clou...|Gabor Bota <gabor...|        bgaborg|\n",
      "|    <jhc@apache.org>|      hadoop|  [<jhc@apache.org>]|James Clampffer <...|               |\n",
      "+--------------------+------------+--------------------+--------------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sampled_authors_grouped_by_author_id_flattened.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1535"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_authors_grouped_by_author_id_flattened.cache()\n",
    "sampled_authors_grouped_by_author_id_flattened.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join the sampled authors with the e-mails on the dev list and find the top 3 most recent responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- project_name: string (nullable = true)\n",
      " |-- box_type: string (nullable = true)\n",
      " |-- mbox_id: string (nullable = true)\n",
      " |-- backend_name: string (nullable = true)\n",
      " |-- backend_version: string (nullable = true)\n",
      " |-- category: string (nullable = true)\n",
      " |-- data: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: string (valueContainsNull = true)\n",
      " |-- origin: string (nullable = true)\n",
      " |-- perceval_version: string (nullable = true)\n",
      " |-- tag: string (nullable = true)\n",
      " |-- timestamp: double (nullable = true)\n",
      " |-- updated_on: double (nullable = true)\n",
      " |-- uuid: string (nullable = true)\n",
      " |-- from: string (nullable = true)\n",
      " |-- from_processed_email: string (nullable = true)\n",
      " |-- body: string (nullable = true)\n",
      " |-- message_id: string (nullable = true)\n",
      " |-- in_reply_to: string (nullable = true)\n",
      " |-- content_language: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mailing_list_posts_mbox_df_saved.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(new_unique_id,StringType,true),StructField(projects,StringType,false),StructField(emails,ArrayType(StringType,true),true),StructField(Author,StringType,true),StructField(github_username,StringType,true)))"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_authors_grouped_by_author_id_flattened.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_posts_by_authors(authors):\n",
    "    join_conditions = [\n",
    "        #sampled_authors_saved.project_name == mailing_list_posts_mbox_df_saved.project_name,\n",
    "        F.expr(\"array_contains(emails, from_processed_email)\")]\n",
    "    return authors.join(mailing_list_posts_mbox_df_saved, join_conditions).select(\n",
    "        \"message_id\", \"new_unique_id\").alias(\"posts_by_sampled_authors\")\n",
    "\n",
    "posts_by_sampled_authors = extract_posts_by_authors(\n",
    "    sampled_authors_grouped_by_author_id_flattened).alias(\n",
    "    \"posts_by_sampled_authors\").cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reusing\n"
     ]
    }
   ],
   "source": [
    "posts_by_sampled_authors_saved = non_blocking_df_save_or_load(\n",
    "    posts_by_sampled_authors, \"{0}/posts_by_sampled_authors_5\".format(fs_prefix)).alias(\"posts_by_sampled_authors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(message_id,StringType,true),StructField(new_unique_id,StringType,true)))"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_by_sampled_authors_saved.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "mailing_list_posts_in_reply_to = mailing_list_posts_mbox_df_saved.filter(\n",
    "    mailing_list_posts_mbox_df_saved.in_reply_to.isNotNull()).alias(\"mailing_list_posts_in_reply_to\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_5k_chars(tokens):\n",
    "    return tokens[0:5000]\n",
    "\n",
    "first_5k_chars_udf = UserDefinedFunction(\n",
    "    first_5k_chars,\n",
    "    StringType(),\n",
    "    \"first_5k_chars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_pronoun(tokens):\n",
    "    common_pronouns = [\"they\", \"ze\", \"he\", \"she\", \"her\", \"his\", \"their\"]\n",
    "    return any(pronoun in tokens for pronoun in common_pronouns)\n",
    "\n",
    "contains_pronoun_udf = UserDefinedFunction(\n",
    "    contains_pronoun,\n",
    "    BooleanType(),\n",
    "    \"contains_pronoun\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relevant_posts_with_replies(mailing_list_posts_in_reply_to, posts):\n",
    "    \n",
    "    posts_with_replies = posts.join(\n",
    "        mailing_list_posts_in_reply_to,\n",
    "        [F.col(\"mailing_list_posts_in_reply_to.in_reply_to\") == posts.message_id],\n",
    "        \"inner\")\n",
    "    posts_in_response_to_user = posts_with_replies.select(\n",
    "        posts_with_replies.new_unique_id,\n",
    "        posts_with_replies.timestamp,\n",
    "        posts_with_replies.project_name,\n",
    "        posts_with_replies.body.alias(\"orig_body\"),\n",
    "        first_5k_chars_udf(posts_with_replies.body).alias(\"body\"))\n",
    "    posts_in_response_to_user.cache()\n",
    "    \n",
    "    from sparklingml.feature.python_pipelines import SpacyTokenizeTransformer\n",
    "    spacy_tokenizer = SpacyTokenizeTransformer(inputCol=\"body\", outputCol=\"body_tokens\")\n",
    "    \n",
    "    posts_in_response_to_user_tokenized = spacy_tokenizer.transform(\n",
    "        posts_in_response_to_user)\n",
    "    posts_in_response_to_user_tokenized.cache()\n",
    "    # Need to break the chain... its not great.\n",
    "    \n",
    "    posts_in_response_to_user_with_pronouns = posts_in_response_to_user_tokenized.filter(\n",
    "        contains_pronoun_udf(posts_in_response_to_user_tokenized.body_tokens))\n",
    "    # nyet\n",
    "    posts_in_response_to_user_with_pronouns.cache()\n",
    "    #return posts_in_response_to_user_with_pronouns\n",
    "\n",
    "    posts_in_response_to_user_grouped = posts_in_response_to_user_with_pronouns.orderBy(\n",
    "        posts_in_response_to_user.timestamp).groupBy(\n",
    "        posts_in_response_to_user.new_unique_id)\n",
    "    posts_in_response_to_user_collected = posts_in_response_to_user_grouped.agg(\n",
    "        F.collect_list(posts_in_response_to_user_with_pronouns.body).alias(\"emails\"))\n",
    "    # nyet\n",
    "    return posts_in_response_to_user_collected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using backing jar /sparklingml/sparklingml/../target/scala-2.11/sparklingml-assembly-0.0.1-SNAPSHOT.jar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reusing\n"
     ]
    }
   ],
   "source": [
    "mailing_list_posts_in_reply_to.cache().count()\n",
    "posts_by_sampled_authors.cache().count()\n",
    "posts_in_response_to_user_collected = relevant_posts_with_replies(\n",
    "    mailing_list_posts_in_reply_to, posts_by_sampled_authors)\n",
    "#posts_in_response_to_user_collected.first()\n",
    "posts_in_response_to_user_collected_saved = non_blocking_df_save_or_load(\n",
    "    posts_in_response_to_user_collected,\n",
    "    \"{0}/posts_by_user_9\".format(fs_prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- new_unique_id: string (nullable = true)\n",
      " |-- emails: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "posts_in_response_to_user_collected_saved.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|       new_unique_id|              emails|\n",
      "+--------------------+--------------------+\n",
      "|<vozerov@gridgain...|[{plain=Hi,\n",
      "\n",
      "I go...|\n",
      "|<jcustenborder@gm...|[{plain=On 06/07/...|\n",
      "| <jdeppe@pivotal.io>|[{plain=HI Jens,\r",
      "...|\n",
      "|              yew1eb|[{plain=Congrats ...|\n",
      "|<cchampeau@apache...|[{plain=On 09.04....|\n",
      "|           ArnaudFnr|[{plain=This is a...|\n",
      "|<progers@maprtech...|[{plain=Just thou...|\n",
      "|<zhaijia@apache.org>|[{plain=+1 (non b...|\n",
      "| <nreich@pivotal.io>|[{plain=The packa...|\n",
      "|         qianzhangxa|[{plain=I comment...|\n",
      "|<gaston@mesospher...|[{plain=The ASF m...|\n",
      "|<ssainath@hortonw...|[{plain=Congratul...|\n",
      "|<peng.jianhua@zte...|[{plain=\n",
      "--------...|\n",
      "|<awong@cloudera.com>|[{plain=>\n",
      "> How d...|\n",
      "|<sboikov@apache.org>|[{plain=I don't t...|\n",
      "|<mgergely@hortonw...|[{plain=Thanks Mi...|\n",
      "|<ekl@databricks.com>|[{plain=Hi Eric,\n",
      "...|\n",
      "|           hachikuji|[{plain=I agree w...|\n",
      "|<vovatkach75@gmai...|[{plain=I’d be op...|\n",
      "|               sijie|[{plain=If I reme...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "posts_in_response_to_user_collected.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#posts_in_response_to_user_collected.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------+------+------+---------------+-------------+\n",
      "|project_name|new_unique_id|emails|Author|github_username|latest_commit|\n",
      "+------------+-------------+------+------+---------------+-------------+\n",
      "+------------+-------------+------+------+---------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sampled_authors_saved.filter(sampled_authors_saved.new_unique_id == \"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a sample for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first10(posts):\n",
    "    return posts[0:10]\n",
    "first10_udf = UserDefinedFunction(\n",
    "    first10,\n",
    "    ArrayType(StringType()),\n",
    "    \"first10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_posts_for_user = posts_in_response_to_user_collected_saved.select(\n",
    "    posts_in_response_to_user_collected_saved.new_unique_id,\n",
    "    first10_udf(posts_in_response_to_user_collected_saved.emails).alias(\"top10emails\")).alias(\"top_posts_for_user\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_sample = sampled_authors_saved.join(\n",
    "    top_posts_for_user,\n",
    "    top_posts_for_user.new_unique_id == sampled_authors_saved.new_unique_id,\n",
    "    \"LEFT_OUTER\").select(\n",
    "    \"project_name\",\n",
    "    F.col(\"sampled_authors.new_unique_id\").alias(\"id\"),\n",
    "    \"Author\",\n",
    "    \"github_username\",\n",
    "    \"top10emails\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reusing\n"
     ]
    }
   ],
   "source": [
    "joined_sample_saved = non_blocking_df_save_or_load(\n",
    "    joined_sample,\n",
    "    \"{0}/joined_sample_3\".format(fs_prefix)).alias(\"joined_sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+--------------------+---------------+--------------------+\n",
      "|project_name|                  id|              Author|github_username|         top10emails|\n",
      "+------------+--------------------+--------------------+---------------+--------------------+\n",
      "|      bigtop|  <530590615@qq.com>|zhtisi <530590615...|               |                null|\n",
      "|       arrow|<antoine@python.org>|Antoine Pitrou <a...|               |[{plain=My feelin...|\n",
      "|       nutch|<bvachon@attivio....|Ben Vachon <bvach...|               |[{plain=Hi Ben\n",
      "\n",
      "O...|\n",
      "|    notebook|<danalee96@gmail....|danagilliann <dan...|               |                null|\n",
      "|        hive| <kb.pcre@gmail.com>|Bertalan Kondrat ...|               |                null|\n",
      "|      ambari|<smolnar@hortonwo...|Sandor Molnar <sm...|               |[{plain=+1\r\n",
      "\r\n",
      "On ...|\n",
      "|       hbase|<swilson@siftscie...|Scott Wilson <swi...|               |                null|\n",
      "|       hbase|<tianjy1990@gmail...|tianjingyun <tian...|               |                null|\n",
      "|       drill|<vitalii.diravka@...|Vitalii Diravka <...|               |[{plain=sounds go...|\n",
      "|     calcite|<vitalii.diravka@...|Vitalii Diravka <...|               |[{plain=sounds go...|\n",
      "|       camel|            cunningt|Tom Cunningham <t...|       cunningt|[{plain=Tom, not ...|\n",
      "|         cxf|               jimma|Jim Ma <ema@apach...|          jimma|                null|\n",
      "|        nifi|       ottobackwards|Otto Fowler <otto...|  ottobackwards|[{plain=Note:  Gr...|\n",
      "|       storm|             ptgoetz|P. Taylor Goetz <...|        ptgoetz|[{plain=Thanks! T...|\n",
      "|       flink|            tzulitai|Tzu-Li (Gordon) T...|       tzulitai|[{plain=Hi Gordon...|\n",
      "|        hive|  <daijyc@gmail.com>|Daniel Dai <daijy...|               |[{plain=\n",
      "\n",
      "> On No...|\n",
      "|     calcite| <ebegoli@gmail.com>|Edmon Begoli <ebe...|               |[{plain=Edmon,\n",
      "\n",
      "I...|\n",
      "|       geode|<jbarrett@pivotal...|Jacob Barrett <jb...|               |[{plain=After fur...|\n",
      "|       httpd| <rpluem@apache.org>|Ruediger Pluem <r...|               |[{plain=On Sun, 0...|\n",
      "|       nutch|<yossi.tamari@pip...|Yossi Tamari <yos...|               |[{plain=You shoul...|\n",
      "+------------+--------------------+--------------------+---------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joined_sample_saved.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "@F.pandas_udf(StringType())\n",
    "def create_email_snippet(emails):\n",
    "    import os\n",
    "    def create_snippet(email):\n",
    "        if email is None:\n",
    "            return email\n",
    "        #result = email.replace(os.linesep, ' ')\n",
    "        # IDK but seems required for the other system :(\n",
    "        #result = result.replace('\\n', ' ')\n",
    "        #result = result.replace('\\r', ' ')\n",
    "        #result = result.replace(',', ' ')\n",
    "        #result = result.replace(',', ' ')\n",
    "        result = email\n",
    "        import string\n",
    "        printable = set(string.printable)\n",
    "        result = ''.join(filter(lambda x: x in printable, result))\n",
    "        if len(result) > 500:\n",
    "            result = result[0:500] + \"..... e-mail condensed for readability\"\n",
    "        return result\n",
    "    return emails.apply(create_snippet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.getConf().get(\"spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_sample = joined_sample_saved.select(\n",
    "    \"project_name\",\n",
    "    \"id\",\n",
    "    \"Author\",\n",
    "    \"github_username\",\n",
    "    create_email_snippet(joined_sample_saved.top10emails[0]).alias(\"email0\"),\n",
    "    create_email_snippet(joined_sample_saved.top10emails[1]).alias(\"email1\"),\n",
    "    create_email_snippet(joined_sample_saved.top10emails[2]).alias(\"email2\")).cache().repartition(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+--------------------+---------------+--------------------+--------------------+--------------------+\n",
      "| project_name|                  id|              Author|github_username|              email0|              email1|              email2|\n",
      "+-------------+--------------------+--------------------+---------------+--------------------+--------------------+--------------------+\n",
      "|   cloudstack|<daan.hoogland@sh...|Daan Hoogland <da...|               |{plain=So here is...|{plain=You unders...|{plain=Will great...|\n",
      "|          cxf|<freeman.fang@gma...|Freeman Fang <fre...|               |{plain=Hi Freeman...|{plain=+1\n",
      "\n",
      "On Thu...|{plain=+1\n",
      "\n",
      "On Thu...|\n",
      "|    cassandra|    <mck@apache.org>|Mick Semb Wever <...|               |{plain=On 04/12/2...|{plain=On 12-09-0...|{plain=On Wed, 20...|\n",
      "|        hbase|<thiruvel@gmail.com>|Thiruvel Thirumoo...|               |                null|                null|                null|\n",
      "|       groovy|<nikchugunov@gith...|Nikolay Chugunov ...|               |                null|                null|                null|\n",
      "|        camel|       <rovo@gmx.at>|Roman Vottner <ro...|               |                null|                null|                null|\n",
      "|        camel|<sebastien.beaume...|BEAUME <sebastien...|               |                null|                null|                null|\n",
      "|        samza| <navina@apache.org>|navina <navina@ap...|               |{plain=Hey Navina...|{plain=Thanks muc...|{plain=Hey Navina...|\n",
      "|       impala|   <lv@cloudera.com>|Lars Volker <lv@c...|               |{plain=+1\n",
      "\n",
      "Obviou...|{plain=@Lars Volk...|{plain=That looks...|\n",
      "|        spark|<marcogaido91@gma...|Marco Gaido <marc...|               |{plain=Thank you ...|{plain=Congrats a...|{plain=Java 9/10 ...|\n",
      "|        drill|<rajrahul@gmail.com>|Rahul Raj <rajrah...|               |{plain=Have you l...|{plain=I was sugg...|                null|\n",
      "|   bookkeeper|<cguttapalem@sale...|cguttapalem <cgut...|               |                null|                null|                null|\n",
      "|        hbase|<weichiu@cloudera...|Wei-Chiu Chuang <...|               |{plain=Thanks for...|{plain=>From TD p...|{plain=Not yet.  ...|\n",
      "|        kafka|                dguy|Damian Guy <damia...|           dguy|{plain=Thanks Dam...|{plain=Damian,\n",
      "\n",
      "T...|{plain=>> The key...|\n",
      "|trafficserver|            shinrich|Susan Hinrichs <s...|       shinrich|{plain=All right,...|{plain=Originally...|                null|\n",
      "|        kafka|<asutosh.pandya@h...|asutosh936 <asuto...|               |                null|                null|                null|\n",
      "|        geode| <jiliao@pivotal.io>|jinmeiliao <jilia...|               |{plain=\n",
      "\n",
      "> On Jun...|{plain=fix for th...|{plain=\n",
      "---------...|\n",
      "|   bookkeeper|           eolivelli|Enrico Olivelli <...|      eolivelli|{plain=Enrico,\n",
      "\n",
      "C...|{plain=>>but ther...|{plain=>>maybe yo...|\n",
      "|        karaf|<luke@code-house....|Łukasz Dywicki <l...|               |{plain=On Tuesday...|{plain=Yes. I thi...|{plain=2011/1/20 ...|\n",
      "|       thrift|<kerri.devine@sie...|Kerri Devine <ker...|               |                null|                null|                null|\n",
      "+-------------+--------------------+--------------------+---------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "formatted_sample.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reusing\n"
     ]
    }
   ],
   "source": [
    "formatted_sample_pq_saved = non_blocking_df_save_or_load(\n",
    "    formatted_sample,\n",
    "    \"{0}/formatted_sample_pq_11\".format(fs_prefix))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def html_escape(raw_string):\n",
    "    import html\n",
    "    if raw_string is None:\n",
    "        return raw_string\n",
    "    initial_escape = html.escape(raw_string)\n",
    "    return initial_escape.replace(os.linesep, '<br>').replace('\\n', '').replace('\\r', '')\n",
    "html_escape_udf = UserDefinedFunction(\n",
    "      html_escape,\n",
    "      StringType(),\n",
    "      \"html_escape_udf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reusing\n"
     ]
    }
   ],
   "source": [
    "escaped = formatted_sample_pq_saved.select(\n",
    "    list(map(lambda col: html_escape_udf(col).alias(col), formatted_sample_pq_saved.columns)))\n",
    "formatted_sample_csv_saved = non_blocking_df_save_or_load_csv(\n",
    "    escaped,\n",
    "    \"{0}/formatted_sample_csv_14\".format(fs_prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "projects = formatted_sample_pq_saved.groupBy(\n",
    "    formatted_sample_pq_saved.project_name).agg(F.first(\"project_name\")).select(\"project_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[project_name: string]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reusing\n"
     ]
    }
   ],
   "source": [
    "projects_csv = non_blocking_df_save_or_load_csv(projects, \"{0}/projects\".format(fs_prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projects_csv.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load back the human processed data & process the columns into formats that are easier with Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewrite_human_data(df):\n",
    "    columns = df.columns\n",
    "    candidates_to_select = filter(lambda column: \"Input\" in column or \"Answer\" in column, columns)\n",
    "\n",
    "    def easy_name(column_name):\n",
    "        return column_name.replace(\".\", \"_\")\n",
    "    \n",
    "    rewrite_literals = map(\n",
    "        lambda column_name: F.col(\"`{0}`\".format(column_name)).alias(easy_name(column_name)),\n",
    "        candidates_to_select)\n",
    "    return df.select(*list(rewrite_literals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_human_raw_df = session.read.format(\"csv\").option(\"header\", \"true\") \\\n",
    "                .option(\"inferSchema\", \"true\").load(\n",
    "    \"{0}/human_data/projects\".format(fs_prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reusing\n"
     ]
    }
   ],
   "source": [
    "project_human_df = non_blocking_df_save_or_load(\n",
    "    rewrite_human_data(project_human_raw_df),\n",
    "    \"{0}/human_data_cleaned/projects\".format(fs_prefix))                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_contirbutors_human_raw_df = session.read.format(\"csv\").option(\"header\", \"true\") \\\n",
    "                .option(\"inferSchema\", \"true\").load(\n",
    "    \"{0}/human_data/sampled_contirbutors\".format(fs_prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reusing\n"
     ]
    }
   ],
   "source": [
    "sampled_contirbutors_human_df = non_blocking_df_save_or_load(\n",
    "    rewrite_human_data(sampled_contirbutors_human_raw_df),\n",
    "    \"{0}/human_data_cleaned/sampled_contributors\".format(fs_prefix)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "asf_people_human_raw_df = session.read.format(\"csv\").option(\"header\", \"true\") \\\n",
    "                .option(\"inferSchema\", \"true\").load(\n",
    "    \"{0}/human_data/asf_people\".format(fs_prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reusing\n"
     ]
    }
   ],
   "source": [
    "asf_people_human_df = non_blocking_df_save_or_load(\n",
    "    rewrite_human_data(asf_people_human_raw_df),\n",
    "    \"{0}/human_data_cleaned/asf_people\".format(fs_prefix)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------------------+---------------------------------+----------------------+---------------------------------+-------------------------+------------------------------------+--------------------+----------------------+---------------------------------+\n",
      "|Input_project|Answer_code_of_conduct|Answer_code_of_conduct_difficulty|Answer_committer_guide|Answer_committer_guide_difficulty|Answer_contributing_guide|Answer_contributing_guide_difficulty|     Answer_feedback|Answer_mentoring_guide|Answer_mentoring_guide_difficulty|\n",
      "+-------------+----------------------+---------------------------------+----------------------+---------------------------------+-------------------------+------------------------------------+--------------------+----------------------+---------------------------------+\n",
      "|     accumulo|                  none|                             hard|  https://accumulo....|                             easy|     https://accumulo....|                                easy|                  NA|                  none|                             hard|\n",
      "|     airavata|                  none|                             hard|                  none|                             hard|     https://airavata....|                                easy|                  NA|                  none|                             hard|\n",
      "|       ambari|                  none|                             hard|                  none|                             hard|                     none|                                hard|                None|                  none|                             hard|\n",
      "|        arrow|                  none|                             hard|  https://arrow.apa...|                             easy|     https://arrow.apa...|                                easy|                  NA|                  none|                             hard|\n",
      "|    asterixdb|                  none|                             hard|  https://asterixdb...|                             easy|     https://asterixdb...|                                easy|It will be great ...|                  none|                             hard|\n",
      "|        atlas|                  none|                             hard|                  none|                             hard|                     none|                                hard|                  NA|                  none|                             hard|\n",
      "|         beam|                  none|                             hard|  https://beam.apac...|                             easy|     https://beam.apac...|                                easy|                  NA|                  none|                             hard|\n",
      "|       bigtop|                  none|                             hard|  https://cwiki.apa...|                             easy|     https://cwiki.apa...|                                easy|                  NA|                  none|                             hard|\n",
      "|   bookkeeper|  https://bookkeepe...|                             Easy|                  none|                             hard|     https://bookkeepe...|                                easy|                none|                  none|                             hard|\n",
      "|   bookkeeper|                  none|                             hard|  https://bookkeepe...|                             easy|     https://bookkeepe...|                                easy|                  NA|                  none|                             hard|\n",
      "|      calcite|                  none|                             hard|  https://community...|                             easy|     https://calcite.a...|                                easy|                  NA|                  none|                             hard|\n",
      "|        camel|                  none|                             hard|  http://camel.apac...|                             easy|     http://camel.apac...|                                easy|                  NA|                  none|                             hard|\n",
      "|   carbondata|                  none|                             hard|  https://carbondat...|                             easy|     https://github.co...|                                easy|           no issues|                  none|                             hard|\n",
      "|    cassandra|  https://whimsy.ap...|                             easy|  https://wiki.apac...|                             easy|     https://wiki.apac...|                                easy|           no issues|                  none|                             hard|\n",
      "|   cloudstack|                  none|                             hard|                  none|                             hard|                     none|                                hard|Perhaps you could...|                  none|                             hard|\n",
      "|      couchdb|  http://couchdb.ap...|                             easy|                  none|                             hard|     http://couchdb.ap...|                                easy|                  NA|                  none|                             hard|\n",
      "|          cxf|                  none|                             hard|                  none|                             hard|     http://cxf.apache...|                                easy|                  NA|                  none|                             hard|\n",
      "|        drill|                  none|                             hard|                  none|                             hard|     https://drill.apa...|                                easy|                  NA|                  none|                             hard|\n",
      "|        flink|                  none|                             hard|  https://flink.apa...|                             easy|     https://flink.apa...|                                easy|                None|                  none|                             hard|\n",
      "|        geode|  https://cwiki-tes...|                             easy|  http://incubator....|                             easy|     https://cwiki-tes...|                                easy|           no issues|  https://cwiki.apa...|                             easy|\n",
      "+-------------+----------------------+---------------------------------+----------------------+---------------------------------+-------------------------+------------------------------------+--------------------+----------------------+---------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "project_human_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_maybe_link(col):\n",
    "    if col is None:\n",
    "        return None\n",
    "    cleaned_ish = col.lower()\n",
    "    if cleaned_ish == \"none\" or cleaned_ish == \"na\":\n",
    "        return None\n",
    "    if \"http://\" in cleaned_ish or \"https://\" in cleaned_ish:\n",
    "        return cleaned_ish\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "clean_maybe_link_udf = UserDefinedFunction(\n",
    "    clean_maybe_link, StringType(), \"clean_maybe_link_field\")\n",
    "\n",
    "def clean_difficulty(col):\n",
    "    if col is None:\n",
    "        return None\n",
    "    cleaned_ish = col.lower()\n",
    "    if cleaned_ish == \"none\" or cleaned_ish == \"na\":\n",
    "        return None\n",
    "    return ''.join(cleaned_ish.split(' '))\n",
    "\n",
    "clean_difficulty_udf = UserDefinedFunction(\n",
    "    clean_difficulty, StringType(), \"clean_difficulty_field\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_column(f):\n",
    "    if f == \"Input_project\":\n",
    "        return F.col(\"Input_project\").alias(\"project\")\n",
    "    elif \"Input\" in f:\n",
    "        return f\n",
    "    elif \"difficulty\" in f:\n",
    "        return clean_difficulty_udf(f).alias(f)\n",
    "    elif \"Answer_feedback\" in f:\n",
    "        return f\n",
    "    else:\n",
    "        return clean_maybe_link_udf(f).alias(f)\n",
    "project_human_cleaned_df = project_human_df.select(\n",
    "    *list(map(process_column, project_human_df.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------------------+---------------------------------+----------------------+---------------------------------+-------------------------+------------------------------------+--------------------+----------------------+---------------------------------+\n",
      "|   project|Answer_code_of_conduct|Answer_code_of_conduct_difficulty|Answer_committer_guide|Answer_committer_guide_difficulty|Answer_contributing_guide|Answer_contributing_guide_difficulty|     Answer_feedback|Answer_mentoring_guide|Answer_mentoring_guide_difficulty|\n",
      "+----------+----------------------+---------------------------------+----------------------+---------------------------------+-------------------------+------------------------------------+--------------------+----------------------+---------------------------------+\n",
      "|  accumulo|                  null|                             hard|  https://accumulo....|                             easy|     https://accumulo....|                                easy|                  NA|                  null|                             hard|\n",
      "|  airavata|                  null|                             hard|                  null|                             hard|     https://airavata....|                                easy|                  NA|                  null|                             hard|\n",
      "|    ambari|                  null|                             hard|                  null|                             hard|                     null|                                hard|                None|                  null|                             hard|\n",
      "|     arrow|                  null|                             hard|  https://arrow.apa...|                             easy|     https://arrow.apa...|                                easy|                  NA|                  null|                             hard|\n",
      "| asterixdb|                  null|                             hard|  https://asterixdb...|                             easy|     https://asterixdb...|                                easy|It will be great ...|                  null|                             hard|\n",
      "|     atlas|                  null|                             hard|                  null|                             hard|                     null|                                hard|                  NA|                  null|                             hard|\n",
      "|      beam|                  null|                             hard|  https://beam.apac...|                             easy|     https://beam.apac...|                                easy|                  NA|                  null|                             hard|\n",
      "|    bigtop|                  null|                             hard|  https://cwiki.apa...|                             easy|     https://cwiki.apa...|                                easy|                  NA|                  null|                             hard|\n",
      "|bookkeeper|  https://bookkeepe...|                             easy|                  null|                             hard|     https://bookkeepe...|                                easy|                none|                  null|                             hard|\n",
      "|bookkeeper|                  null|                             hard|  https://bookkeepe...|                             easy|     https://bookkeepe...|                                easy|                  NA|                  null|                             hard|\n",
      "|   calcite|                  null|                             hard|  https://community...|                             easy|     https://calcite.a...|                                easy|                  NA|                  null|                             hard|\n",
      "|     camel|                  null|                             hard|  http://camel.apac...|                             easy|     http://camel.apac...|                                easy|                  NA|                  null|                             hard|\n",
      "|carbondata|                  null|                             hard|  https://carbondat...|                             easy|     https://github.co...|                                easy|           no issues|                  null|                             hard|\n",
      "| cassandra|  https://whimsy.ap...|                             easy|  https://wiki.apac...|                             easy|     https://wiki.apac...|                                easy|           no issues|                  null|                             hard|\n",
      "|cloudstack|                  null|                             hard|                  null|                             hard|                     null|                                hard|Perhaps you could...|                  null|                             hard|\n",
      "|   couchdb|  http://couchdb.ap...|                             easy|                  null|                             hard|     http://couchdb.ap...|                                easy|                  NA|                  null|                             hard|\n",
      "|       cxf|                  null|                             hard|                  null|                             hard|     http://cxf.apache...|                                easy|                  NA|                  null|                             hard|\n",
      "|     drill|                  null|                             hard|                  null|                             hard|     https://drill.apa...|                                easy|                  NA|                  null|                             hard|\n",
      "|     flink|                  null|                             hard|  https://flink.apa...|                             easy|     https://flink.apa...|                                easy|                None|                  null|                             hard|\n",
      "|     geode|  https://cwiki-tes...|                             easy|  http://incubator....|                             easy|     https://cwiki-tes...|                                easy|           no issues|  https://cwiki.apa...|                             easy|\n",
      "+----------+----------------------+---------------------------------+----------------------+---------------------------------+-------------------------+------------------------------------+--------------------+----------------------+---------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "project_human_cleaned_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_gender_field(column):\n",
    "    if column is None:\n",
    "        return \"na\"\n",
    "    lowered = column.lower()\n",
    "    if \"female\" in lowered or \"woman\" in lowered or \"she\" in lowered or \"her\" in lowered or lowered == \"f\":\n",
    "        return \"female\"\n",
    "    elif \"enby\" in lowered or \"non-binary\" in lowered or \"they\" in lowered:\n",
    "        return \"enby\"\n",
    "    elif lowered == \"m\" or \"male\" in lowered or \"https://www.linkedin.com/in/moonsoo-lee-4982a511/\" in lowered:\n",
    "        return \"male\"\n",
    "    elif \"n/a\" in lowered or \"na\" in lowered:\n",
    "        return \"na\"\n",
    "    else:\n",
    "        return lowered\n",
    "clean_gender_field_udf = UserDefinedFunction(clean_gender_field, StringType(), \"clean_gender_field\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_asf_people_human_df = asf_people_human_df.select(\"*\",\n",
    "                           clean_gender_field_udf(\"Answer_gender\").alias(\"cleaned_gender\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reusing\n"
     ]
    }
   ],
   "source": [
    "cleaned_asf_people_human_df_saved = non_blocking_df_save_or_load(\n",
    "    cleaned_asf_people_human_df,\n",
    "    \"{0}/human_data_cleaned/asf_people_cleaned\".format(fs_prefix)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2565"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_asf_people_human_df_saved.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_sampled_contirbutors_human_df = sampled_contirbutors_human_df.select(\n",
    "    \"*\",\n",
    "    clean_gender_field_udf(\"Answer_gender\").alias(\"cleaned_gender\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reusing\n"
     ]
    }
   ],
   "source": [
    "cleaned_sampled_contirbutors_human_df_saved = non_blocking_df_save_or_load(\n",
    "    cleaned_sampled_contirbutors_human_df,\n",
    "    \"{0}/human_data_cleaned/sampled_contirbutors_cleaned\".format(fs_prefix)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by_gender(df):\n",
    "    return df.groupBy(df.cleaned_gender).agg(F.count(df.cleaned_gender))\n",
    "def group_by_project_count_gender(df):\n",
    "    by_gender_and_project = df.withColumn(\n",
    "        \"projects_array\",\n",
    "        F.split(df.Input_projects, \" \")).select(\n",
    "        \"*\",\n",
    "        F.explode(\"projects_array\").alias(\"project\")).groupBy(\n",
    "        \"project\").agg(\n",
    "          F.sum((df.cleaned_gender == \"male\").cast(\"long\")).alias(\"male\"),\n",
    "          F.sum((df.cleaned_gender == \"na\").cast(\"long\")).alias(\"unknown\"),\n",
    "          F.sum((df.cleaned_gender == \"enby\").cast(\"long\")).alias(\"enby\"),\n",
    "          F.sum((df.cleaned_gender == \"female\").cast(\"long\")).alias(\"female\"))\n",
    "    pre_result = by_gender_and_project.select(\n",
    "        \"*\",\n",
    "        ((by_gender_and_project.enby + by_gender_and_project.female) /\n",
    "         (by_gender_and_project.male + by_gender_and_project.enby + by_gender_and_project.female)))\n",
    "    result = pre_result.select(\n",
    "    F.col(\"*\"), F.col(\"((enby + female) / ((male + enby) + female))\").alias(\"nonmale_percentage\"))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "#group_by_project_count_gender(cleaned_asf_people_human_df).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reusing\n"
     ]
    }
   ],
   "source": [
    "asf_agg_by_gender_df = non_blocking_df_save_or_load_csv(\n",
    "    group_by_gender(cleaned_asf_people_human_df).repartition(1),\n",
    "    \"{0}/asf_people_cleaned_agg_by_gender_3c\".format(fs_prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asf_agg_by_gender_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reusing\n"
     ]
    }
   ],
   "source": [
    "asf_agg_by_gender_and_proj_df = non_blocking_df_save_or_load_csv(\n",
    "    group_by_project_count_gender(cleaned_asf_people_human_df_saved).repartition(1),\n",
    "    \"{0}/asf_people_cleaned_agg_by_gender_and_proj_3c\".format(fs_prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----+-------+----+------+--------------------------------------------+--------------------+\n",
      "|      project|male|unknown|enby|female|((enby + female) / ((male + enby) + female))|  nonmale_percentage|\n",
      "+-------------+----+-------+----+------+--------------------------------------------+--------------------+\n",
      "|         lucy|  11|      0|   0|     1|                         0.08333333333333333| 0.08333333333333333|\n",
      "|    chemistry|  30|      3|   0|     3|                         0.09090909090909091| 0.09090909090909091|\n",
      "|      vxquery|   7|      0|   0|     0|                                         0.0|                 0.0|\n",
      "|       roller|   5|      0|   0|     0|                                         0.0|                 0.0|\n",
      "|       falcon|  17|      0|   0|     0|                                         0.0|                 0.0|\n",
      "|        geode|  39|      1|   0|     6|                         0.13333333333333333| 0.13333333333333333|\n",
      "|trafficserver|  34|      3|   0|     4|                         0.10526315789473684| 0.10526315789473684|\n",
      "|          tez|  32|      1|   0|     2|                        0.058823529411764705|0.058823529411764705|\n",
      "|       pdfbox|  19|      1|   0|     1|                                        0.05|                0.05|\n",
      "|        httpd|  51|      0|   0|     0|                                         0.0|                 0.0|\n",
      "|   carbondata|   8|      0|   0|     3|                          0.2727272727272727|  0.2727272727272727|\n",
      "|        celix|   6|      0|   0|     1|                         0.14285714285714285| 0.14285714285714285|\n",
      "|     accumulo|  32|      1|   0|     1|                        0.030303030303030304|0.030303030303030304|\n",
      "|       wicket|  29|      1|   0|     0|                                         0.0|                 0.0|\n",
      "|   servicemix|  21|      1|   0|     1|                        0.045454545454545456|0.045454545454545456|\n",
      "|        twill|   6|      0|   0|     0|                                         0.0|                 0.0|\n",
      "|     clerezza|   9|      0|   0|     0|                                         0.0|                 0.0|\n",
      "|      couchdb|  11|      0|   0|     4|                         0.26666666666666666| 0.26666666666666666|\n",
      "|       bigtop|  25|      1|   0|     0|                                         0.0|                 0.0|\n",
      "|     marmotta|  10|      1|   0|     0|                                         0.0|                 0.0|\n",
      "+-------------+----+-------+----+------+--------------------------------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "asf_agg_by_gender_and_proj_df.select(\"*\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(Input_project_name,StringType,true),StructField(Input_id,StringType,true),StructField(Input_Author,StringType,true),StructField(Input_github_username,StringType,true),StructField(Input_email0,StringType,true),StructField(Input_email1,StringType,true),StructField(Input_email2,StringType,true),StructField(Answer_feedback,StringType,true),StructField(Answer_gender,StringType,true),StructField(Answer_web_urls,StringType,true),StructField(cleaned_gender,StringType,true)))"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_sampled_contirbutors_human_df_saved.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled = cleaned_sampled_contirbutors_human_df_saved \\\n",
    "  .withColumn(\n",
    "    \"Input_projects\",\n",
    "    cleaned_sampled_contirbutors_human_df_saved.Input_project_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reusing\n"
     ]
    }
   ],
   "source": [
    "sampled_contirbutors_human_agg_by_gender_and_proj_df = non_blocking_df_save_or_load_csv(\n",
    "    group_by_project_count_gender(sampled).repartition(1),\n",
    "    \"{0}/sampled_contirbutors_human_agg_by_gender_and_proj_3c\".format(fs_prefix)).alias(\"sampled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+-------+----+------+--------------------------------------------+--------------------+\n",
      "|   project|male|unknown|enby|female|((enby + female) / ((male + enby) + female))|  nonmale_percentage|\n",
      "+----------+----+-------+----+------+--------------------------------------------+--------------------+\n",
      "|  zeppelin|  21|      0|   0|     0|                                         0.0|                 0.0|\n",
      "|    bigtop|  11|      0|   0|     1|                         0.08333333333333333| 0.08333333333333333|\n",
      "|     arrow|  41|      1|   0|     1|                        0.023809523809523808|0.023809523809523808|\n",
      "|  airavata|   9|      0|   0|    14|                          0.6086956521739131|  0.6086956521739131|\n",
      "|     kafka|  56|      2|   0|     6|                          0.0967741935483871|  0.0967741935483871|\n",
      "|       cxf|  24|      0|   0|     0|                                         0.0|                 0.0|\n",
      "|  libcloud|  21|      0|   0|     0|                                         0.0|                 0.0|\n",
      "|     atlas|  12|      1|   0|     1|                         0.07692307692307693| 0.07692307692307693|\n",
      "|      hive|  34|      0|   0|     4|                         0.10526315789473684| 0.10526315789473684|\n",
      "|   couchdb|  19|      0|   0|     3|                         0.13636363636363635| 0.13636363636363635|\n",
      "|    thrift|  24|      0|   0|     2|                         0.07692307692307693| 0.07692307692307693|\n",
      "|      kudu|  22|      0|   0|     2|                         0.08333333333333333| 0.08333333333333333|\n",
      "|bookkeeper|  19|      0|   0|     3|                         0.13636363636363635| 0.13636363636363635|\n",
      "|     flink|  49|      1|   1|     2|                        0.057692307692307696|0.057692307692307696|\n",
      "|     drill|  20|      2|   0|     2|                         0.09090909090909091| 0.09090909090909091|\n",
      "|     mesos|  43|      0|   0|     1|                        0.022727272727272728|0.022727272727272728|\n",
      "|     karaf|  16|      0|   0|     1|                        0.058823529411764705|0.058823529411764705|\n",
      "|    wicket|  12|      0|   0|     2|                         0.14285714285714285| 0.14285714285714285|\n",
      "|  accumulo|  12|      0|   0|     0|                                         0.0|                 0.0|\n",
      "|     storm|  27|      0|   0|     3|                                         0.1|                 0.1|\n",
      "+----------+----+-------+----+------+--------------------------------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sampled_contirbutors_human_agg_by_gender_and_proj_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attempt to infer Gender off of name. This has problems, see https://ironholds.org/names-gender/ for a discussion on why this is problematic, but if it matches our statistical samples from above it can augment our understanding of the data. However without doing this it's difficult to get much of a picture (see above where we attempt to gender from other sources, the hit rate leaves something to be desired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_name_info(input_elem):\n",
    "    from nameparser import HumanName\n",
    "    # Kind of a hack but wing seems like a commen name more than a title.\n",
    "    from nameparser.config import CONSTANTS\n",
    "    CONSTANTS.titles.remove('hon')\n",
    "    CONSTANTS.titles.remove('wing')\n",
    "    if \" <\" in input_elem:\n",
    "        name_chunk = input_elem.split(\" <\")[0]\n",
    "    elif \"<\" in input_elem:\n",
    "        name_chunk = input_elem.split(\"<\")[0]\n",
    "    else:\n",
    "        name_chunk = input_elem\n",
    "    if \" \" not in name_chunk and \".\" in name_chunk:\n",
    "        # Handle the convention[ish] of names of first.last\n",
    "        name_chunk = name_chunk.replace(\".\", \" \")\n",
    "    parsed = HumanName(name_chunk)\n",
    "    return {\"title\": parsed.title, \"first\": parsed.first}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_name_info_udf = UserDefinedFunction(\n",
    "    parse_name_info,\n",
    "    StructType([StructField(\"title\", StringType()), StructField(\"first\", StringType())]),\n",
    "    \"parse_name_info\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_with_name = authors_grouped_by_id_saved.select(\n",
    "    \"*\", parse_name_info_udf(\"Author\").alias(\"parsed_info\")).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----+\n",
      "|          first|title|\n",
      "+---------------+-----+\n",
      "|          Dylan|     |\n",
      "|          Mario|     |\n",
      "|           Chad|     |\n",
      "|       adeneche|     |\n",
      "|       Ashutosh|     |\n",
      "|         Venkat|     |\n",
      "|        Nicolás|     |\n",
      "|         Selvin|     |\n",
      "|        cpovirk|     |\n",
      "|          Pawel|     |\n",
      "|          Wenwu|     |\n",
      "|       Valentin|     |\n",
      "|  Serhii-Harnyk|     |\n",
      "|         Thopap|     |\n",
      "|  juanjovazquez|     |\n",
      "|        nkukhar|     |\n",
      "|           Doug|     |\n",
      "|SRIGOPALMOHANTY|     |\n",
      "| vincentchenfei|     |\n",
      "|       Matthias|     |\n",
      "+---------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "authors_with_name.select(\"parsed_info.first\", \"parsed_info.title\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+\n",
      "|   first|names_count|\n",
      "+--------+-----------+\n",
      "|   David|        154|\n",
      "| Michael|        123|\n",
      "|    John|        118|\n",
      "|  Daniel|        111|\n",
      "|  Andrew|        106|\n",
      "|   Chris|         99|\n",
      "|    Mark|         91|\n",
      "|    Alex|         81|\n",
      "|   Peter|         79|\n",
      "|    Paul|         75|\n",
      "|  Thomas|         74|\n",
      "|   Jason|         73|\n",
      "|  Robert|         73|\n",
      "|   James|         72|\n",
      "|    Mike|         66|\n",
      "|Jonathan|         61|\n",
      "|     Joe|         57|\n",
      "|   Brian|         57|\n",
      "|  Martin|         56|\n",
      "|    Sean|         56|\n",
      "+--------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "names_count = authors_with_name.groupBy(\"parsed_info.first\").agg(F.count(\"*\").alias(\"names_count\"))\n",
    "names_count.sort(names_count.names_count.desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authors_with_name.filter(authors_with_name.parsed_info.title != \"\").select(\"parsed_info.first\", \"parsed_info.title\", \"Author\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "@F.pandas_udf(StringType())\n",
    "def lookup_gender_from_name(names):\n",
    "    # Uses https://pypi.org/project/gender-guesser/ based on https://autohotkey.com/board/topic/20260-gender-verification-by-forename-cmd-line-tool-db/\n",
    "    import gender_guesser.detector as gender\n",
    "    d = gender.Detector()\n",
    "    def inner_detect_gender(name):\n",
    "        fname = name.split(\" \")[0]\n",
    "        return d.get_gender(fname)\n",
    "    return names.apply(inner_detect_gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup_gender_from_name_genderize(name):\n",
    "    from genderize import Genderize\n",
    "    result = Genderize(api_key=genderize_key).get([name])[0]\n",
    "    if result['gender'] is not None:\n",
    "        return result\n",
    "    else:\n",
    "        return {\"name\": name, \"gender\": None, \"probability\": None, \"count\": 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup_gender_from_name_genderize_udf = UserDefinedFunction(\n",
    "    lookup_gender_from_name_genderize,\n",
    "    StructType([StructField(\"name\", StringType()), StructField(\"gender\", StringType()),\n",
    "               StructField(\"probability\", DoubleType()), StructField(\"count\", IntegerType())\n",
    "               ]),\n",
    "    \"lookup_gender_from_name_genderize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cache to break pipeline and mix UDF types\n",
    "infered_gender_for_authors = authors_with_name.withColumn(\n",
    "    \"infered_gender\",\n",
    "    lookup_gender_from_name(\"parsed_info.first\")) \\\n",
    "    .cache() \\\n",
    "    .withColumn(\n",
    "    \"genderize_results\",\n",
    "    lookup_gender_from_name_genderize_udf(\"parsed_info.first\")).cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reusing\n"
     ]
    }
   ],
   "source": [
    "infered_gender_for_authors_pq_saved = non_blocking_df_save_or_load(\n",
    "    infered_gender_for_authors,\n",
    "    \"{0}/infered_gender_for_authors_pq_3\".format(fs_prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(project_name='accumulo', new_unique_id='<dhutchis@mit.edu>', emails=['<dhutchis@mit.edu>'], Author='Dylan Hutchison <dhutchis@mit.edu>', github_username='', latest_commit=datetime.date(2015, 1, 2), parsed_info=Row(title='', first='Dylan'), infered_gender='mostly_male', genderize_results=Row(name='Dylan', gender='male', probability=0.99, count=785)),\n",
       " Row(project_name='accumulo', new_unique_id='<mario.pastorelli@teralytics.ch>', emails=['<mario.pastorelli@teralytics.ch>'], Author='Mario Pastorelli <mario.pastorelli@teralytics.ch>', github_username='', latest_commit=datetime.date(2015, 12, 30), parsed_info=Row(title='', first='Mario'), infered_gender='male', genderize_results=Row(name='Mario', gender='male', probability=0.99, count=2026)),\n",
       " Row(project_name='activemq', new_unique_id='<czobrisky@gmail.com>', emails=['<czobrisky@gmail.com>'], Author='Chad Zobrisky <czobrisky@gmail.com>', github_username='', latest_commit=datetime.date(2014, 12, 31), parsed_info=Row(title='', first='Chad'), infered_gender='male', genderize_results=Row(name='Chad', gender='male', probability=1.0, count=1028)),\n",
       " Row(project_name='arrow', new_unique_id='<adeneche@dremio.com>', emails=['<adeneche@dremio.com>'], Author='adeneche <adeneche@dremio.com>', github_username='', latest_commit=datetime.date(2017, 1, 6), parsed_info=Row(title='', first='adeneche'), infered_gender='unknown', genderize_results=Row(name='adeneche', gender=None, probability=None, count=0)),\n",
       " Row(project_name='atlas', new_unique_id='<amestry@apache.org>', emails=['<amestry@apache.org>'], Author='Ashutosh Mestry <amestry@apache.org>', github_username='', latest_commit=datetime.date(2017, 1, 6), parsed_info=Row(title='', first='Ashutosh'), infered_gender='male', genderize_results=Row(name='Ashutosh', gender='male', probability=1.0, count=129))]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infered_gender_for_authors_pq_saved.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "infered_relevant_info = infered_gender_for_authors_pq_saved.select(\n",
    "    infered_gender_for_authors_pq_saved.project_name,\n",
    "    infered_gender_for_authors_pq_saved.Author,\n",
    "    infered_gender_for_authors_pq_saved.new_unique_id,\n",
    "    infered_gender_for_authors_pq_saved.latest_commit,\n",
    "    infered_gender_for_authors_pq_saved.parsed_info.title.alias(\"title\"),\n",
    "    infered_gender_for_authors_pq_saved.infered_gender,\n",
    "    infered_gender_for_authors_pq_saved.genderize_results.gender.alias(\"genderize_gender\"),\n",
    "    infered_gender_for_authors_pq_saved.genderize_results.probability.alias(\"genderize_prob\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+--------------------+-------------+-----+--------------+----------------+--------------+\n",
      "|project_name|              Author|       new_unique_id|latest_commit|title|infered_gender|genderize_gender|genderize_prob|\n",
      "+------------+--------------------+--------------------+-------------+-----+--------------+----------------+--------------+\n",
      "|    accumulo|Dylan Hutchison <...|  <dhutchis@mit.edu>|   2015-01-02|     |   mostly_male|            male|          0.99|\n",
      "|    accumulo|Mario Pastorelli ...|<mario.pastorelli...|   2015-12-30|     |          male|            male|          0.99|\n",
      "|    activemq|Chad Zobrisky <cz...|<czobrisky@gmail....|   2014-12-31|     |          male|            male|           1.0|\n",
      "|       arrow|adeneche <adenech...|<adeneche@dremio....|   2017-01-06|     |       unknown|            null|          null|\n",
      "|       atlas|Ashutosh Mestry <...|<amestry@apache.org>|   2017-01-06|     |          male|            male|           1.0|\n",
      "|       atlas|Venkat Ranganatha...|<venkat@hortonwor...|   2015-01-02|     |          male|            male|           1.0|\n",
      "|      aurora|Nicolás Donatucci...|<ndonatucci@medal...|   2017-01-03|     |          male|            null|          null|\n",
      "|      aurora|Selvin George <sg...|<sgeorge@twitter....|   2013-01-05|     |       unknown|            male|          0.96|\n",
      "|        beam|cpovirk <cpovirk@...|<cpovirk@google.com>|   2016-01-01|     |       unknown|            null|          null|\n",
      "|        beam|Pawel Kaczmarczyk...|<p.kaczmarczyk@oc...|   2018-01-02|     |          male|            male|          0.98|\n",
      "|      bigtop|Wenwu Peng <pengw...|<pengwenwu2008@16...|   2014-01-02|     |       unknown|            null|          null|\n",
      "|    brooklyn|Valentin Aitken <...|  <bostko@gmail.com>|   2014-12-30|     |          male|            male|           1.0|\n",
      "|     calcite|Serhii-Harnyk <se...|<serhii.harnyk@gm...|   2015-12-29|     |       unknown|            null|          null|\n",
      "|       camel|Thopap <Thomas.pa...|<Thomas.papke@icw...|   2017-01-03|     |       unknown|            null|          null|\n",
      "|       camel|juanjovazquez <jv...|<jvazquez@tecsisa...|   2014-01-01|     |       unknown|            null|          null|\n",
      "|       camel|nkukhar <kukhar.n...|             nkukhar|   2015-01-02|     |       unknown|            null|          null|\n",
      "|       camel|Doug Turnbull <dt...|        softwaredoug|   2014-01-04|     |          male|            male|           1.0|\n",
      "|  carbondata|SRIGOPALMOHANTY <...|<SRIGOPALMOHANTY@...|   2017-01-03|     |       unknown|            null|          null|\n",
      "|  carbondata|vincentchenfei <v...|<vincent.chenfei@...|   2017-01-03|     |       unknown|            null|          null|\n",
      "|   cassandra|Matthias Weiser <...|<MWeiser@ardmoref...|   2018-01-02|     |          male|            male|           1.0|\n",
      "+------------+--------------------+--------------------+-------------+-----+--------------+----------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "infered_relevant_info.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------+\n",
      "|genderize_gender|count(1)|\n",
      "+----------------+--------+\n",
      "|            null|    3892|\n",
      "|          female|    1040|\n",
      "|            male|   10508|\n",
      "+----------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "infered_relevant_info.groupBy(infered_relevant_info.genderize_gender).agg(F.count(\"*\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------+\n",
      "|infered_gender|count(1)|\n",
      "+--------------+--------+\n",
      "| mostly_female|      90|\n",
      "|       unknown|    5759|\n",
      "|        female|     434|\n",
      "|          andy|     396|\n",
      "|          male|    8249|\n",
      "|   mostly_male|     512|\n",
      "+--------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "infered_relevant_info.groupBy(infered_relevant_info.infered_gender).agg(F.count(\"*\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_info = infered_relevant_info.withColumn(\n",
    "    \"Input_projects\",\n",
    "    infered_relevant_info.project_name).withColumn(\n",
    "    \"cleaned_gender\",\n",
    "    clean_gender_field_udf(\"genderize_gender\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reusing\n"
     ]
    }
   ],
   "source": [
    "relevant_info_agg_by_gender_and_proj_df = non_blocking_df_save_or_load_csv(\n",
    "    group_by_project_count_gender(relevant_info).repartition(1),\n",
    "    \"{0}/relevant_info_agg_by_gender_and_proj_3c\".format(fs_prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+-------+----+------+--------------------------------------------+--------------------+\n",
      "|   project|male|unknown|enby|female|((enby + female) / ((male + enby) + female))|  nonmale_percentage|\n",
      "+----------+----+-------+----+------+--------------------------------------------+--------------------+\n",
      "|      reef|  42|     31|   0|     8|                                        0.16|                0.16|\n",
      "|   myfaces|  39|      3|   0|     1|                                       0.025|               0.025|\n",
      "|    groovy| 210|     55|   0|     5|                        0.023255813953488372|0.023255813953488372|\n",
      "|   phoenix|  66|     24|   0|     1|                        0.014925373134328358|0.014925373134328358|\n",
      "| trafodion|  71|     49|   0|    36|                          0.3364485981308411|  0.3364485981308411|\n",
      "| asterixdb|  46|     33|   0|     1|                         0.02127659574468085| 0.02127659574468085|\n",
      "|     pivot|  10|      2|   0|     1|                         0.09090909090909091| 0.09090909090909091|\n",
      "|freemarker|   9|     10|   0|     0|                                         0.0|                 0.0|\n",
      "|      fluo|  19|      4|   0|     2|                         0.09523809523809523| 0.09523809523809523|\n",
      "|  notebook| 245|     73|   0|    23|                         0.08582089552238806| 0.08582089552238806|\n",
      "|      hive| 150|     53|   0|    18|                         0.10714285714285714| 0.10714285714285714|\n",
      "| chemistry|  12|      0|   0|     0|                                         0.0|                 0.0|\n",
      "|   vxquery|   7|      7|   0|     2|                          0.2222222222222222|  0.2222222222222222|\n",
      "|     hbase| 194|    100|   0|    24|                         0.11009174311926606| 0.11009174311926606|\n",
      "|       ant|  46|     11|   0|     4|                                        0.08|                0.08|\n",
      "|    falcon|  32|     14|   0|     9|                         0.21951219512195122| 0.21951219512195122|\n",
      "|     geode|  91|     33|   0|    12|                         0.11650485436893204| 0.11650485436893204|\n",
      "|    crunch|  52|      7|   0|     0|                                         0.0|                 0.0|\n",
      "|subversion|  69|     13|   0|     1|                        0.014285714285714285|0.014285714285714285|\n",
      "|      drat|  16|     12|   0|     1|                        0.058823529411764705|0.058823529411764705|\n",
      "+----------+----+-------+----+------+--------------------------------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "relevant_info_agg_by_gender_and_proj_df.alias(\"infered\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see what's correlated - TODO loop this over the different types of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_sampled_and_infered = sampled_contirbutors_human_agg_by_gender_and_proj_df.join(\n",
    "    relevant_info_agg_by_gender_and_proj_df,\n",
    "    on=\"project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_with_project_info = sampled_contirbutors_human_agg_by_gender_and_proj_df.join(\n",
    "    project_human_cleaned_df,\n",
    "    on=\"project\").join(\n",
    "    agg_post_sentiment,\n",
    "    on=\"project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+-------+----+------+--------------------------------------------+-------------------+----------------------+---------------------------------+----------------------+---------------------------------+-------------------------+------------------------------------+--------------------+----------------------+---------------------------------+------------+-----------------+--------------------+--------------------+-----------------+-------------------+--------------------+------------------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "|   project|male|unknown|enby|female|((enby + female) / ((male + enby) + female))| nonmale_percentage|Answer_code_of_conduct|Answer_code_of_conduct_difficulty|Answer_committer_guide|Answer_committer_guide_difficulty|Answer_contributing_guide|Answer_contributing_guide_difficulty|     Answer_feedback|Answer_mentoring_guide|Answer_mentoring_guide_difficulty|project_name|sentiment.neg_max|   sentiment.neg_avg|       neg_quantiles|sentiment.pos_max|  sentiment.pos_avg|       pos_quantiles|sentiment.neg_25quantile|sentiment.neg_50quantile|sentiment.neg_75quantile|sentiment.pos_25quantile|sentiment.pos_50quantile|sentiment.pos_75quantile|\n",
      "+----------+----+-------+----+------+--------------------------------------------+-------------------+----------------------+---------------------------------+----------------------+---------------------------------+-------------------------+------------------------------------+--------------------+----------------------+---------------------------------+------------+-----------------+--------------------+--------------------+-----------------+-------------------+--------------------+------------------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "|cloudstack|  29|      1|   0|     2|                         0.06451612903225806|0.06451612903225806|                  null|                             hard|                  null|                             hard|                     null|                                hard|Perhaps you could...|                  null|                             hard|  cloudstack|            0.374|0.030660410167236668|[0.011, 0.027, 0.04]|            0.416|0.07643164731754547|[0.011, 0.027, 0.04]|                   0.011|                   0.027|                    0.04|                   0.011|                   0.027|                    0.04|\n",
      "|     hbase|  54|      2|   0|     1|                         0.01818181818181818|0.01818181818181818|  https://hbase.apa...|                             easy|  https://hbase.apa...|                             easy|     https://hbase.apa...|                                easy|           no issues|  https://hbase.apa...|                             easy|       hbase|            0.336|0.047520055452864765| [0.0, 0.029, 0.058]|            0.419| 0.0648682994454709| [0.0, 0.029, 0.058]|                     0.0|                   0.029|                   0.058|                     0.0|                   0.029|                   0.058|\n",
      "|      hive|  34|      0|   0|     4|                         0.10526315789473684|0.10526315789473684|                  null|                             hard|  https://cwiki.apa...|                             easy|     https://cwiki.apa...|                                easy|                  NA|                  null|                             hard|        hive|            0.299|0.031159021113243708| [0.0, 0.022, 0.048]|            0.744| 0.0713851247600767| [0.0, 0.022, 0.048]|                     0.0|                   0.022|                   0.048|                     0.0|                   0.022|                   0.048|\n",
      "|   phoenix|  22|      0|   0|     0|                                         0.0|                0.0|                  null|                             hard|                  null|                             hard|     https://phoenix.a...|                                easy|                  NA|                  null|                             hard|     phoenix|            0.278|  0.0286186250280833| [0.0, 0.019, 0.278]|            0.604|0.06938373399236117| [0.0, 0.019, 0.278]|                     0.0|                   0.019|                   0.278|                     0.0|                   0.019|                   0.278|\n",
      "|     spark|  76|      1|   0|     5|                         0.06172839506172839|0.06172839506172839|                  null|                             hard|  https://spark.apa...|                             easy|     https://spark.apa...|                                easy|                  NA|                  null|                             hard|       spark|            0.297|0.029928716020821203|[0.006, 0.023, 0....|            0.503|0.08106636784268348|[0.006, 0.023, 0....|                   0.006|                   0.023|                   0.297|                   0.006|                   0.023|                   0.297|\n",
      "+----------+----+-------+----+------+--------------------------------------------+-------------------+----------------------+---------------------------------+----------------------+---------------------------------+-------------------------+------------------------------------+--------------------+----------------------+---------------------------------+------------+-----------------+--------------------+--------------------+-----------------+-------------------+--------------------+------------------------+------------------------+------------------------+------------------------+------------------------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joined_with_project_info.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "def flatmap(f, items):\n",
    "        return chain.from_iterable(map(f, items))\n",
    "\n",
    "def compute_new_columns(df):\n",
    "    columns = df.columns\n",
    "    def compute_numeric_columns(column):\n",
    "        if \"Answer_\" in column and not \"feedback\" in column and not \"_difficulty\" in column:\n",
    "            return [\n",
    "                (~ F.isnull(F.col(\"`{0}`\".format(column)))).cast(\"long\").alias(column+\"_exists\"),\n",
    "                (~ F.isnull(F.col(\"`{0}`\".format(column))) & (F.col(column + \"_difficulty\") == \"easy\")).cast(\"long\").alias(column+\"_easy\")]\n",
    "        return []\n",
    "    my_columns = list(flatmap(compute_numeric_columns, columns))\n",
    "    my_columns.append(\"*\")\n",
    "    return df.select(*my_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_df = compute_new_columns(joined_with_project_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[nonmale_percentage: double]"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_df.select(\"`nonmale_percentage`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_aggs = [\n",
    "    F.corr(\"`nonmale_percentage`\", \"Answer_mentoring_guide_exists\"),\n",
    "    F.corr(\"`nonmale_percentage`\", \"Answer_mentoring_guide_easy\"),\n",
    "    F.corr(\"`nonmale_percentage`\", \"Answer_contributing_guide_exists\"),\n",
    "    F.corr(\"`nonmale_percentage`\", \"Answer_contributing_guide_easy\"),\n",
    "    F.corr(\"`nonmale_percentage`\", \"Answer_committer_guide_exists\"),\n",
    "    F.corr(\"`nonmale_percentage`\", \"Answer_committer_guide_easy\"),\n",
    "    F.corr(\"`nonmale_percentage`\", \"Answer_code_of_conduct_exists\"),\n",
    "    F.corr(\"`nonmale_percentage`\", \"Answer_code_of_conduct_easy\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "computed_aggs = map(\n",
    "    lambda c: F.corr(\"`nonmale_percentage`\", \"`{0}`\".format(c)),\n",
    "    filter(lambda c: \"sentiment.pos\" in c or \"sentiment.neg\" in c, numeric_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_aggs = []\n",
    "corr_aggs.extend(manual_aggs)\n",
    "corr_aggs.extend(computed_aggs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------+-----------------------------------------------------+----------------------------------------------------------+--------------------------------------------------------+-------------------------------------------------------+-----------------------------------------------------+-------------------------------------------------------+-----------------------------------------------------+---------------------------------------------+---------------------------------------------+---------------------------------------------+---------------------------------------------+----------------------------------------------------+----------------------------------------------------+----------------------------------------------------+----------------------------------------------------+----------------------------------------------------+----------------------------------------------------+\n",
      "|corr(nonmale_percentage, Answer_mentoring_guide_exists)|corr(nonmale_percentage, Answer_mentoring_guide_easy)|corr(nonmale_percentage, Answer_contributing_guide_exists)|corr(nonmale_percentage, Answer_contributing_guide_easy)|corr(nonmale_percentage, Answer_committer_guide_exists)|corr(nonmale_percentage, Answer_committer_guide_easy)|corr(nonmale_percentage, Answer_code_of_conduct_exists)|corr(nonmale_percentage, Answer_code_of_conduct_easy)|corr(nonmale_percentage, `sentiment.neg_max`)|corr(nonmale_percentage, `sentiment.neg_avg`)|corr(nonmale_percentage, `sentiment.pos_max`)|corr(nonmale_percentage, `sentiment.pos_avg`)|corr(nonmale_percentage, `sentiment.neg_25quantile`)|corr(nonmale_percentage, `sentiment.neg_50quantile`)|corr(nonmale_percentage, `sentiment.neg_75quantile`)|corr(nonmale_percentage, `sentiment.pos_25quantile`)|corr(nonmale_percentage, `sentiment.pos_50quantile`)|corr(nonmale_percentage, `sentiment.pos_75quantile`)|\n",
      "+-------------------------------------------------------+-----------------------------------------------------+----------------------------------------------------------+--------------------------------------------------------+-------------------------------------------------------+-----------------------------------------------------+-------------------------------------------------------+-----------------------------------------------------+---------------------------------------------+---------------------------------------------+---------------------------------------------+---------------------------------------------+----------------------------------------------------+----------------------------------------------------+----------------------------------------------------+----------------------------------------------------+----------------------------------------------------+----------------------------------------------------+\n",
      "|                                    -0.4269689320917422|                                  -0.4269689320917422|                                       -0.1960081503782872|                                     -0.1960081503782872|                                    0.38817892141801813|                                  0.38817892141801813|                                    -0.4269689320917422|                                  -0.4269689320917422|                          0.14828713581114342|                          -0.3173698896837277|                           0.4197358881824746|                          0.47326922463905635|                                  0.2790390742164674|                                0.018343520672052468|                                   -0.41192296901851|                                  0.2790390742164674|                                0.018343520672052468|                                   -0.41192296901851|\n",
      "+-------------------------------------------------------+-----------------------------------------------------+----------------------------------------------------------+--------------------------------------------------------+-------------------------------------------------------+-----------------------------------------------------+-------------------------------------------------------+-----------------------------------------------------+---------------------------------------------+---------------------------------------------+---------------------------------------------+---------------------------------------------+----------------------------------------------------+----------------------------------------------------+----------------------------------------------------+----------------------------------------------------+----------------------------------------------------+----------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "numeric_df.agg(*corr_aggs).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_cor = numeric_df.agg(*corr_aggs).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(corr(nonmale_percentage, Answer_mentoring_guide_exists)=-0.4269689320917422, corr(nonmale_percentage, Answer_mentoring_guide_easy)=-0.4269689320917422, corr(nonmale_percentage, Answer_contributing_guide_exists)=-0.1960081503782872, corr(nonmale_percentage, Answer_contributing_guide_easy)=-0.1960081503782872, corr(nonmale_percentage, Answer_committer_guide_exists)=0.38817892141801813, corr(nonmale_percentage, Answer_committer_guide_easy)=0.38817892141801813, corr(nonmale_percentage, Answer_code_of_conduct_exists)=-0.4269689320917422, corr(nonmale_percentage, Answer_code_of_conduct_easy)=-0.4269689320917422, corr(nonmale_percentage, `sentiment.neg_max`)=0.14828713581114342, corr(nonmale_percentage, `sentiment.neg_avg`)=-0.3173698896837277, corr(nonmale_percentage, `sentiment.pos_max`)=0.4197358881824746, corr(nonmale_percentage, `sentiment.pos_avg`)=0.47326922463905635, corr(nonmale_percentage, `sentiment.neg_25quantile`)=0.2790390742164674, corr(nonmale_percentage, `sentiment.neg_50quantile`)=0.018343520672052468, corr(nonmale_percentage, `sentiment.neg_75quantile`)=-0.41192296901851, corr(nonmale_percentage, `sentiment.pos_25quantile`)=0.2790390742164674, corr(nonmale_percentage, `sentiment.pos_50quantile`)=0.018343520672052468, corr(nonmale_percentage, `sentiment.pos_75quantile`)=-0.41192296901851)]"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corr(nonmale_percentage, Answer_mentoring_guide_exists)</th>\n",
       "      <th>corr(nonmale_percentage, Answer_mentoring_guide_easy)</th>\n",
       "      <th>corr(nonmale_percentage, Answer_contributing_guide_exists)</th>\n",
       "      <th>corr(nonmale_percentage, Answer_contributing_guide_easy)</th>\n",
       "      <th>corr(nonmale_percentage, Answer_committer_guide_exists)</th>\n",
       "      <th>corr(nonmale_percentage, Answer_committer_guide_easy)</th>\n",
       "      <th>corr(nonmale_percentage, Answer_code_of_conduct_exists)</th>\n",
       "      <th>corr(nonmale_percentage, Answer_code_of_conduct_easy)</th>\n",
       "      <th>corr(nonmale_percentage, `sentiment.neg_max`)</th>\n",
       "      <th>corr(nonmale_percentage, `sentiment.neg_avg`)</th>\n",
       "      <th>corr(nonmale_percentage, `sentiment.pos_max`)</th>\n",
       "      <th>corr(nonmale_percentage, `sentiment.pos_avg`)</th>\n",
       "      <th>corr(nonmale_percentage, `sentiment.neg_25quantile`)</th>\n",
       "      <th>corr(nonmale_percentage, `sentiment.neg_50quantile`)</th>\n",
       "      <th>corr(nonmale_percentage, `sentiment.neg_75quantile`)</th>\n",
       "      <th>corr(nonmale_percentage, `sentiment.pos_25quantile`)</th>\n",
       "      <th>corr(nonmale_percentage, `sentiment.pos_50quantile`)</th>\n",
       "      <th>corr(nonmale_percentage, `sentiment.pos_75quantile`)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.426969</td>\n",
       "      <td>-0.426969</td>\n",
       "      <td>-0.196008</td>\n",
       "      <td>-0.196008</td>\n",
       "      <td>0.388179</td>\n",
       "      <td>0.388179</td>\n",
       "      <td>-0.426969</td>\n",
       "      <td>-0.426969</td>\n",
       "      <td>0.148287</td>\n",
       "      <td>-0.31737</td>\n",
       "      <td>0.419736</td>\n",
       "      <td>0.473269</td>\n",
       "      <td>0.279039</td>\n",
       "      <td>0.018344</td>\n",
       "      <td>-0.411923</td>\n",
       "      <td>0.279039</td>\n",
       "      <td>0.018344</td>\n",
       "      <td>-0.411923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   corr(nonmale_percentage, Answer_mentoring_guide_exists)  \\\n",
       "0                                          -0.426969         \n",
       "\n",
       "   corr(nonmale_percentage, Answer_mentoring_guide_easy)  \\\n",
       "0                                          -0.426969       \n",
       "\n",
       "   corr(nonmale_percentage, Answer_contributing_guide_exists)  \\\n",
       "0                                          -0.196008            \n",
       "\n",
       "   corr(nonmale_percentage, Answer_contributing_guide_easy)  \\\n",
       "0                                          -0.196008          \n",
       "\n",
       "   corr(nonmale_percentage, Answer_committer_guide_exists)  \\\n",
       "0                                           0.388179         \n",
       "\n",
       "   corr(nonmale_percentage, Answer_committer_guide_easy)  \\\n",
       "0                                           0.388179       \n",
       "\n",
       "   corr(nonmale_percentage, Answer_code_of_conduct_exists)  \\\n",
       "0                                          -0.426969         \n",
       "\n",
       "   corr(nonmale_percentage, Answer_code_of_conduct_easy)  \\\n",
       "0                                          -0.426969       \n",
       "\n",
       "   corr(nonmale_percentage, `sentiment.neg_max`)  \\\n",
       "0                                       0.148287   \n",
       "\n",
       "   corr(nonmale_percentage, `sentiment.neg_avg`)  \\\n",
       "0                                       -0.31737   \n",
       "\n",
       "   corr(nonmale_percentage, `sentiment.pos_max`)  \\\n",
       "0                                       0.419736   \n",
       "\n",
       "   corr(nonmale_percentage, `sentiment.pos_avg`)  \\\n",
       "0                                       0.473269   \n",
       "\n",
       "   corr(nonmale_percentage, `sentiment.neg_25quantile`)  \\\n",
       "0                                           0.279039      \n",
       "\n",
       "   corr(nonmale_percentage, `sentiment.neg_50quantile`)  \\\n",
       "0                                           0.018344      \n",
       "\n",
       "   corr(nonmale_percentage, `sentiment.neg_75quantile`)  \\\n",
       "0                                          -0.411923      \n",
       "\n",
       "   corr(nonmale_percentage, `sentiment.pos_25quantile`)  \\\n",
       "0                                           0.279039      \n",
       "\n",
       "   corr(nonmale_percentage, `sentiment.pos_50quantile`)  \\\n",
       "0                                           0.018344      \n",
       "\n",
       "   corr(nonmale_percentage, `sentiment.pos_75quantile`)  \n",
       "0                                          -0.411923     "
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_df.agg(*corr_aggs).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}